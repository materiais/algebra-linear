\documentclass[12pt,a4paper]{article}
\usepackage{cmap} % Makes the PDF copiable. See http://tex.stackexchange.com/a/64198/25761
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp} % \degree
\usepackage{gensymb} % \degree
\usepackage[usenames,svgnames,dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[margin=2cm]{geometry}
\usepackage{systeme}

\hypersetup{
    colorlinks = true,
    allcolors = {blue}
}

\newcommand{\fixme}{{\color{red}(...)}}
\newcommand*\sen{\operatorname{sen}}

\newcommand*\R{\mathbb{R}}

\newcommand{\IconPc}{\includegraphics[width=1em]{computer.png}}
\newcommand{\IconCalc}{\includegraphics[width=1em]{calculator.png}}
\newcommand{\IconThink}{\includegraphics[width=1em]{pencil.png}}
\newcommand{\IconCheck}{\includegraphics[width=1em]{checkmark.png}}
\newcommand{\IconConcept}{\includegraphics[width=1em]{edit.png}}

\newlength{\SmileysLength}
\setlength{\SmileysLength}{\labelwidth}\addtolength{\SmileysLength}{\labelsep}

\newcommand{\calc}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCalc}%
   \hspace*{\SmileysLength}}
\newcommand{\software}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconPc}%
   \hspace*{\SmileysLength}}
\newcommand{\teoria}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconThink}%
   \hspace*{\SmileysLength}}
\newcommand{\conceito}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCheck}%
   \hspace*{\SmileysLength}}
\newcommand{\concept}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCheck}%
   \hspace*{\SmileysLength}}

% Loop Space / CC BY-SA-3.0 / https://tex.stackexchange.com/a/2238/25761
\newenvironment{amatrix}[1]{%
  \left[\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right]
}

% Loop Space / CC BY-SA-3.0 / https://tex.stackexchange.com/a/3164/25761
%--------grstep
% For denoting a Gauss' reduction step.
% Use as: \grstep{\rho_1+\rho_3} or \grstep[2\rho_5 \\ 3\rho_6]{\rho_1+\rho_3}
\newcommand{\grstep}[2][\relax]{%
   \ensuremath{\mathrel{
       {\mathop{\longrightarrow}\limits^{#2\mathstrut}_{
                                     \begin{subarray}{l} #1 \end{subarray}}}}}}
\newcommand{\swap}{\leftrightarrow}

\newcommand*\disciplina{ALI0001}
\newcommand*\tipo{Lista de Exercícios - Matrizes Inversas}
\newcommand*\eu{Helder G. G. de Lima}
\newcommand*\data{\today}

\author{\eu}
\title{\tipo}
\date{\data}

\begin{document}

\begin{center}
\includegraphics[width=9.0cm]{marca} \\
\textbf{\tipo} \\
Prof. \eu\footnote{
Este é um material de acesso livre distribuído sob os termos da licença \href{https://creativecommons.org/licenses/by-sa/4.0/deed.pt_BR}{Creative Commons BY-SA 4.0}}
\end{center}

\section*{Legenda}
\begin{multicols}{4}
\begin{itemize}
\item[] \hspace*{\SmileysLength} \calc \hspace*{-\SmileysLength} Cálculos
\item[] \hspace*{\SmileysLength} \conceito \hspace*{-\SmileysLength} Conceitos
\item[] \hspace*{\SmileysLength} \teoria \hspace*{-\SmileysLength} Teoria
\item[] \hspace*{\SmileysLength} \software \hspace*{-\SmileysLength} Software
\end{itemize}
\end{multicols}

\section*{Questões}

\begin{enumerate}
\item \conceito
Exiba matrizes quadradas $A$ e $B$ de ordem $2 \times 2$ que exemplifiquem as situações a seguir. Compare com o que ocorreria se $A$ e $B$ fossem números reais.

\begin{enumerate}
\item Mesmo que $A \neq B$ pode existir uma matriz $P$ tal que $A = P^{-1}BP$.
\end{enumerate}

\item \calc Calcule, se existir, a inversa de cada uma das matrizes a seguir:
\begin{multicols}{3}
\begin{enumerate}
\item
 $D =
\begin{bmatrix}
1 & -2 & -3\\
1 & -3 & 2\\
-2 & 4 & 5
\end{bmatrix}$
\item $T =
\begin{bmatrix}
0 &  0 &  1 & 0\\
0 &  1 &  1 & 0\\
1 &  0 & -1 & 1\\
1 & -1 & -2 & 2
\end{bmatrix}$
\item
 $U =
\begin{bmatrix}
0 & 0 &  3 &  3\\
0 & 3 &  0 & -3\\
3 & 3 & -3 & -6\\
0 & 0 &  3 &  6
\end{bmatrix}$
\end{enumerate}
\end{multicols}

\item \calc Calcule a matriz inversa de $P = \begin{bmatrix}
2 &  0 &  0 & 0\\
0 & -2 &  0 & 0\\
0 &  1 &  1 & 0\\
2 & -5 & -1 & 2
\end{bmatrix}$ e verifique que $\det(P^{-1}) = \dfrac{1}{\det(P)}$.

\item \calc Se $M = P Q P^{-1}$, $P =
\begin{bmatrix}
   1 &  0 &  5 &  0\\
   0 &  1 &  0 &  3\\
   0 &  0 & -2 &  2\\
   0 &  0 &  0 &  1
\end{bmatrix}$ e $Q =
\begin{bmatrix}
 1 & -1 & 20 & -7 \\
 3 &  1 & 21 & -1 \\
 0 &  0 & -3 &  1 \\
-1 &  0 & -7 &  1
\end{bmatrix}$, calcule $\det(M)$.

\item \conceito Dê exemplos de matrizes $A$ e $B$ tais que
\begin{enumerate}
\item $A + B$ seja inversível, mas $A$ e $B$ não sejam
\item $A$ e $B$ sejam inversíveis, mas $A+B$ não seja
\item $A$, $B$ e $A+B$ sejam inversíveis
\end{enumerate}

\item \calc Utilize matrizes inversas para resolver os seguintes sistemas lineares (quando for possível).

\begin{multicols}{2}
  \begin{enumerate}
  \item $\left\{
  \begin{aligned}
  5s & {}-{} &  5\pi t & {}={} & -5\pi^2\\
  -s & {}+{} & (\pi+3)t & {}={} & \pi(\pi+6)
  \end{aligned}
  \right.%, \text{ sendo } s,t \in \R
  $

  \item $\systeme{
  4x_1+4x_2 = 16,
  5x_2 -15x_4=2,
  2x_1+2x_2+x_3=12,
  -x_2+8x_4=3/5
  }%, \text{ sendo } x_i \in \Q
  $

  \item $\systeme{
            3x_1-12x_2 -6x_3              +9x_5=-21,
            -x_1 +4x_2 +2x_3              -3x_5=7,
  \frac{1}{2}x_1 -2x_2  -x_3+x_4-\frac{3}{2}x_5=-\frac{5}{2},
           -7x_1+28x_2+15x_3             -23x_5=53
  }%, \text{ sendo } x_i \in \R
  $

  \item $\systeme{
       b+6c= 6,
    a+6b-5c=-3,
  3a+20b-3c= 1
  }%, \text{ sendo } a, b, c \in \R
  $
  \end{enumerate}
\end{multicols}

\item \calc Resolva os seguintes sistemas lineares sobre $\R$, usando matrizes inversas:
\begin{multicols}{3}
\begin{enumerate}
\item $\systeme{
   -y+5z=2,
 x+2y+3z=7,
2x+4y+5z=13
}$
\item $\systeme{
   -v+5w=0,
 u+2v+3w=0,
2u+4v+5w=0
}$
\item $\systeme{
   -q+5r=-2,
 p+2q+3r=3,
2p+4q+5r=1
}$
\end{enumerate}
\end{multicols}

\item \calc Suponha que $M = \begin{bmatrix} -1 & 2 & 3 \\ 2 &-4 & 5 \\ -1 &1 &7\end{bmatrix}$ e $X = \begin{bmatrix} a & b & c \\ d & e& f \\ g &h &i\end{bmatrix} \in M_{3 \times 3}(\R)$ são tais que $M X = I_{3 \times 3}$. Determine $X$, por meio da comparação das entradas de $MX$ e $I$, e depois calcule $XM$.

\item Em um software de computação numérica (GNU Octave\footnote{\url{https://www.gnu.org/software/octave/download.html}}, o Scilab\footnote{\url{http://www.scilab.org/download/latest}}, MatLab, etc):
\begin{enumerate}
\item \software Sortear ao acaso 10 matrizes de ordem $7\times 7$ e verificar quantas delas são inversíveis. \textbf{Dica}: o comando \texttt{rand(m,n)} gera aleatoriamente uma matriz de ordem $m \times n$, e o comando \texttt{det(A)} calcula o determinante da matriz $A$.
\item \software Repetir o experimento anterior com matrizes quadradas de algum outro tamanho. O que ocorre com a maioria das matrizes em cada uma das dimensões consideradas?
\item Escolher matrizes triangulares superiores $A_2$, $A_3$ e $A_4$ de ordens $2 \times 2$, $3 \times 3$ e $4 \times 4$ respectivamente, todas com zeros na diagonal e então:
\begin{enumerate}
\item \software Calcular as potências $A_2^2$, $A_3^3$ e $A_4^4$.
\item \teoria Com base nos resultados obtidos, formule uma conjectura a respeito da $n$-ésima potência das matrizes triangulares superiores $n\times n$, com zeros na diagonal.
\item \teoria Prove que o seu palpite é realmente válido para \textbf{qualquer} matriz nas condições acima (pelo menos nos casos $2 \times 2$ e $3 \times 3$).
\end{enumerate}
\end{enumerate}

\item \calc Para que valor(es) de $t \in \R$ a matriz $T = \begin{bmatrix} -1 & 9 & 1 \\ -1 &t & 3 \\ -1 & 9 &t+1\end{bmatrix}$ é inversível? Qual é a inversa?

\item \calc Existe algum $t \in \R$ para o qual $N = \begin{bmatrix} 2-t & 0 & -4 \\ 6 & 1-t & -15 \\ 2 & 0 & -4-t\end{bmatrix} \in M_{3\times 3}(\R)$ não é inversível?
\end{enumerate}



\newpage
\section*{Respostas}
\begin{enumerate}
\item Há uma infinidade de matrizes que exemplificam a afirmação feita. Segue um exemplo:
\begin{enumerate}

\item Se $P =
\begin{bmatrix}
1 & 2 \\
0 & -1
\end{bmatrix}$ e $B =
\begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}$
então $A = P ^{-1}BP = \begin{bmatrix}
7 & 4 \\
-3 & -2
\end{bmatrix}$ é diferente de $B$.
\end{enumerate}

\item \begin{enumerate}
\item
$D^{-1} = \begin{bmatrix}
-23& -2& -13\\
 -9& -1& -5\\
 -2&  0& -1
\end{bmatrix}$
\item
$T^{-1} = \begin{bmatrix}
 1& -1&  2& -1\\
-1&  1&  0&  0\\
 1&  0&  0&  0\\
 0&  1& -1&  1
\end{bmatrix}$
\item
$U^{-1} = \begin{bmatrix}
 1/3& -1/3& 1/3&    0\\
-1/3&  1/3&   0&  1/3\\
 2/3&    0&   0& -1/3\\
-1/3&    0&   0&  1/3
\end{bmatrix}$
\end{enumerate}

\item $\displaystyle \det(P^{-1}) = -1/8 = \frac{1}{-8} = \frac{1}{\det(P)} = \det(P)^{-1}$

\item $M = \begin{bmatrix}
 1 & -1 &  0 &  1\\
 0 &  1 &  0 & -1\\
-2 &  0 & -1 &  2\\
-1 &  0 &  1 & -1
\end{bmatrix}$ e $\det(M) = \det(P)\det(Q)\det(P^{-1}) = \frac{\det(P)\det(Q)}{\det(P)} = \det(Q) = -1$

\item \begin{enumerate}
\item Se
$A = \begin{bmatrix}
1 & 0 \\
0 & 0
\end{bmatrix}$
e
$B = \begin{bmatrix}
0 & 0 \\
0 & 1
\end{bmatrix}$, então
$A + B
= \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} = I$, que é inversível. Porém, $A$ e $B$ não são inversíveis, já que possuem uma coluna de zeros.

\item Se
$A = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}$
e
$B = \begin{bmatrix}
0 & 1 \\
1 & 0
\end{bmatrix}$, então
$A + B
= \begin{bmatrix}
1 & 1 \\
1 & 1
\end{bmatrix}$ não é inversível, pois $AX = 0$ tem uma solução não nula $X = \begin{bmatrix}
1\\-1
\end{bmatrix}$. Porém, $A = A^{-1}$ e $B = B^{-1}$ são inversíveis.

\item Se
$A = B = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}$, então
$A + B
= \begin{bmatrix}
2 & 0 \\
0 & 2
\end{bmatrix}$ e as matrizes $A$, $B$ e $A+B$ são inversíveis, sendo  $A^{-1} = B^{-1} = I$ e $(A+B)^{-1} = (2I)^{-1} = \frac{1}{2} I$.
\end{enumerate}

\item
\begin{enumerate}
\item Primeiro é preciso determinar a inversa de $A$, e para isso serão usadas as mesmas operações elementares que produziram a forma escalonada reduzida de $A$:
\begin{align*}
\begin{bmatrix}
 5 & -5\pi & 1 & 0\\
-1 & \pi+3 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{5} L_1 }
\begin{bmatrix}
 1 & -\pi & 1/5 & 0 \\
-1 & \pi+3 & 0 & 1
\end{bmatrix}
\grstep{ L_2 + L_1 }
\begin{bmatrix}
1 & -\pi & 1/5 & 0 \\
0 &    3 & 1/5 & 1
\end{bmatrix} \\
&
\grstep{ \frac{1}{3} L_2 }
\begin{bmatrix}
1 & -\pi & 1/5 & 0 \\
0 &    1 & 1/15 & 1/3
\end{bmatrix}
\grstep{ L_1 + \pi L_2 }
\begin{bmatrix}
1 & 0 & 1/5 + \pi/15 & \pi/3 \\
0 & 1 &         1/15 & 1/3
\end{bmatrix}
\end{align*}
Assim, $A^{-1} =
\begin{bmatrix}
1/5 + \pi/15 & \pi/3 \\
        1/15 & 1/3
\end{bmatrix}
=
\frac{1}{15}
\begin{bmatrix}
3 + \pi & 5\pi \\
1       & 5
\end{bmatrix}.$

Sempre que $A X = B$ e $A$ é inversível, vale $X = A^{-1} B$. Assim, para $B = \begin{bmatrix}
-5\pi^2 \\
\pi(\pi+6)
\end{bmatrix}$, tem-se
\[
X
%= A^{-1} B
=
\frac{1}{15}
\begin{bmatrix}
3 + \pi & 5\pi \\
1       & 5
\end{bmatrix}
\cdot
\begin{bmatrix}
-5\pi^2 \\
\pi(\pi+6)
\end{bmatrix}
=
\frac{1}{15}
\begin{bmatrix}
-5\pi^2(3 + \pi) + 5\pi^2(\pi+6) \\
-5\pi^2 + 5\pi(\pi+6)
\end{bmatrix}
=
\begin{bmatrix}
\pi^2 \\
2 \pi
\end{bmatrix}.
\]

\item Primeiro, determina-se $A^{-1}$ usando as mesmas operações elementares que produziram a forma escalonada reduzida de $A$:
\begin{align*}
\begin{bmatrix}
4 &  4 & 0 &   0 & 1 & 0 & 0 & 0 \\
0 &  5 & 0 & -15 & 0 & 1 & 0 & 0 \\
2 &  2 & 1 &   0 & 0 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{4} L_1 }
\begin{bmatrix}
1 &  1 & 0 &   0 & 1/4 & 0 & 0 & 0 \\
0 &  5 & 0 & -15 & 0 & 1 & 0 & 0 \\
2 &  2 & 1 &   0 & 0 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix} \\
\grstep{ L_3 - 2 L_1 }
\begin{bmatrix}
1 &  1 & 0 &   0 & 1/4 & 0 & 0 & 0 \\
0 &  5 & 0 & -15 & 0 & 1 & 0 & 0 \\
0 &  0 & 1 &   0 & -1/2 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{5} L_2 }
\begin{bmatrix}
1 &  1 & 0 &   0 & 1/4 & 0 & 0 & 0 \\
0 &  1 & 0 & -3 & 0 & 1/5 & 0 & 0 \\
0 &  0 & 1 &   0 & -1/2 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix} \\
\grstep{ L_4 + L_2 }
\begin{bmatrix}
1 & 1 & 0 &  0 & 1/4 & 0 & 0 & 0 \\
0 & 1 & 0 & -3 & 0 & 1/5 & 0 & 0 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  5 & 0 & 1/5 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{5} L_4 }
\begin{bmatrix}
1 & 1 & 0 &  0 & 1/4 & 0 & 0 & 0 \\
0 & 1 & 0 & -3 & 0 & 1/5 & 0 & 0 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  1 & 0 & 1/25 & 0 & 1/5
\end{bmatrix} \\
\grstep{ L_2 + 3L_4 }
\begin{bmatrix}
1 & 1 & 0 &  0 & 1/4 & 0 & 0 & 0 \\
0 & 1 & 0 &  0 & 0 & 8/25 & 0 & 3/5 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  1 & 0 & 1/25 & 0 & 1/5
\end{bmatrix}
&
\grstep{ L_1 - L_2 }
\begin{bmatrix}
1 & 0 & 0 &  0 & 1/4 & -8/25 & 0 & -3/5 \\
0 & 1 & 0 &  0 & 0 & 8/25 & 0 & 3/5 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  1 & 0 & 1/25 & 0 & 1/5
\end{bmatrix}
\end{align*}

Assim, $A^{-1} =
\begin{bmatrix}
 1/4 & -8/25 & 0 & -3/5 \\
   0 &  8/25 & 0 & 3/5  \\
-1/2 &     0 & 1 & 0    \\
   0 &  1/25 & 0 & 1/5
\end{bmatrix}
=
\frac{1}{100}
\begin{bmatrix}
 25 & -32 &   0 & -60 \\
  0 &  32 &   0 &  60 \\
-50 &   0 & 100 &   0 \\
  0 &   4 &   0 &  20
\end{bmatrix}$ e a solução $X =
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
x_4
\end{bmatrix}$ do sistema é obtida através da seguinte multiplicação:

\[
X
= A^{-1} B
=
\frac{1}{100}
\begin{bmatrix}
 25 & -32 &   0 & -60 \\
  0 &  32 &   0 &  60 \\
-50 &   0 & 100 &   0 \\
  0 &   4 &   0 &  20
\end{bmatrix}
\cdot
\begin{bmatrix}
16 \\
 2 \\
12 \\
3/5
\end{bmatrix}
=
\frac{1}{100}
\begin{bmatrix}
300 \\
100 \\
400 \\
20
\end{bmatrix}
=
\begin{bmatrix}
3 \\
1 \\
4 \\
1/5
\end{bmatrix}
\]

\item A matriz (não aumentada) associada ao sistema não é quadrada.
\item A matriz associada ao sistema não é inversível, pois sua forma escalonada reduzida não é a matriz identidade.
\end{enumerate}

\item Os três sistemas podem ser escritos na forma $AX=B$ com uma mesma matriz $A = \begin{bmatrix}
0 & -1 & 5 \\
1 & 2 & 3 \\
2 & 4 & 5
\end{bmatrix}$, então será preciso calcular apenas uma matriz inversa:
\begin{align*}
\begin{bmatrix}
0 & -1 & 5 & 1 & 0 & 0\\
1 & 2 & 3 & 0 & 1 & 0\\
2 & 4 & 5 & 0 & 0 & 1
\end{bmatrix}
&
\grstep{ L_1 \swap L2 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & -1 & 5 & 1 & 0 & 0\\
2 & 4 & 5 & 0 & 0 & 1
\end{bmatrix}
\grstep{ L_3 - 2 L1 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & -1 & 5 & 1 & 0 & 0\\
0 & 0 & -1 & 0 & -2 & 1
\end{bmatrix} \\
&
\grstep{ -L_2 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & 1 & -5 & -1 & 0 & 0\\
0 & 0 & -1 & 0 & -2 & 1
\end{bmatrix}
\grstep{ -L_3 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & 1 & -5 & -1 & 0 & 0\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix} \\
&
\grstep{ L2+5L_3 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & 1 & 0 & -1 & 10 & -5\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix}
\grstep{ L_1-3L_3 }
\begin{bmatrix}
1 & 2 & 0 & 0 & -5 & 3\\
0 & 1 & 0 & -1 & 10 & -5\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix} \\
&
\grstep{ L_1-2L_2 }
\begin{bmatrix}
1 & 0 & 0 & 2 & -25 & 13\\
0 & 1 & 0 & -1 & 10 & -5\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix}.
\end{align*}
Disto resulta que $A^{-1} = \begin{bmatrix}
 2 & -25 & 13\\
-1 &  10 & -5\\
 0 & 2 & -1
\end{bmatrix}$.

\begin{enumerate}
\item Se $X = \begin{bmatrix}
x\\
y\\
z
\end{bmatrix}$ e $B = \begin{bmatrix}
2\\
7\\
13
\end{bmatrix}$ então:
$
X
= A^{-1} B
=
\begin{bmatrix}
 2 & -25 & 13\\
-1 &  10 & -5\\
 0 & 2 & -1
\end{bmatrix}
\begin{bmatrix}
2\\
7\\
13
\end{bmatrix}
=
\begin{bmatrix}
-2\\
3\\
1
\end{bmatrix}.
$

\item Se $X = \begin{bmatrix}
u\\
v\\
w
\end{bmatrix}$ e $B = \begin{bmatrix}
0\\
0\\
0
\end{bmatrix}$ então $X = \begin{bmatrix}
0\\
0\\
0
\end{bmatrix}$ pois $A$ é inversível.

\item Se $X = \begin{bmatrix}
p\\
q\\
r
\end{bmatrix}$ e $B = \begin{bmatrix}
-2\\
3\\
1
\end{bmatrix}$ então:
$
X
= A^{-1} B
=
\begin{bmatrix}
 2 & -25 & 13\\
-1 &  10 & -5\\
 0 & 2 & -1
\end{bmatrix}
\begin{bmatrix}
-2\\
3\\
1
\end{bmatrix}
=
\begin{bmatrix}
-66\\
27\\
5
\end{bmatrix}.
$
\end{enumerate}

\item Como
\[
MX = \begin{bmatrix}
-1 &  2 & 3 \\
 2 & -4 & 5 \\
-1 &  1 & 7
\end{bmatrix}
\begin{bmatrix}
a & b & c \\
d & e & f \\
g & h & i
\end{bmatrix}
=
\begin{bmatrix}
-a + 2d + 3g & -b + 2e + 3h & -c + 2f + 3i \\
2a - 4d + 5g & 2b - 4e + 5h & 2c - 4f + 5i \\
-a +  d + 7g & -b +  e + 7h & -c +  f + 7i
\end{bmatrix}
\]
e por hipótese $MX = I$, uma comparação das entradas de $MX$ com as de $I$ mostra que as incógnitas que formam as colunas de $X$ devem ser soluções dos sistemas lineares
\[
\systeme[adg]{
-a + 2d + 3g = 1,
2a - 4d + 5g = 0,
-a +  d + 7g = 0
},
\systeme[adg]{
-a + 2d + 3g = 0,
2a - 4d + 5g = 1,
-a +  d + 7g = 0
} \text{ e }
\systeme[adg]{
-a + 2d + 3g = 0,
2a - 4d + 5g = 1,
-a +  d + 7g = 0
}.
\]

Como todos os sistemas têm a mesma matriz de coeficientes, os três podem ser escalonados simultaneamente como segue:

\begin{align*}
&
\begin{bmatrix}
-1 &  2 & 3 & 1 & 0 & 0\\
 2 & -4 & 5 & 0 & 1 & 0\\
-1 &  1 & 7 & 0 & 0 & 1
\end{bmatrix}
\grstep{ -L_1 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 2 & -4 &  5 &  0 & 1 & 0\\
-1 &  1 &  7 &  0 & 0 & 1
\end{bmatrix} \\
\grstep{ L_2 - 2 L_1 }
& \begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 0 &  0 & 11 &  2 & 1 & 0\\
-1 &  1 &  7 &  0 & 0 & 1
\end{bmatrix}
\grstep{ L_3 + L_1 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 0 &  0 & 11 &  2 & 1 & 0\\
 0 & -1 &  4 & -1 & 0 & 1
\end{bmatrix} \\
\grstep{ L_2 \swap L_3 }
& \begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 0 & -1 &  4 & -1 & 0 & 1\\
 0 &  0 & 11 &  2 & 1 & 0
\end{bmatrix}
\grstep{ -L_2 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 &  0\\
 0 &  1 & -4 &  1 & 0 & -1\\
 0 &  0 & 11 &  2 & 1 &  0
\end{bmatrix} \\
\grstep{ \frac{1}{11} L_3 }
&
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 &  0\\
 0 &  1 & -4 &  1 & 0 & -1\\
 0 &  0 &  1 & 2/11 & 1/11 &  0
\end{bmatrix}
\grstep{ L_2 +4 L_3 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 &  0\\
 0 &  1 &  0 & 19/11 & 4/11 & -1\\
 0 &  0 &  1 & 2/11 & 1/11 &  0
\end{bmatrix} \\
\grstep{ L_1 + 3 L_3 }
&
\begin{bmatrix}
 1 & -2 & 0 & -5/11 & 3/11 &  0\\
 0 &  1 & 0 & 19/11 & 4/11 & -1\\
 0 &  0 & 1 &  2/11 & 1/11 &  0
\end{bmatrix}
\grstep{ L_1 + 2 L_2 }
\begin{bmatrix}
 1 & 0 & 0 & 3 & 1 & -2\\
 0 & 1 & 0 & 19/11 & 4/11 & -1\\
 0 & 0 & 1 &  2/11 & 1/11 &  0
\end{bmatrix}
\end{align*}
Assim,
$X = \begin{bmatrix}
    3 &    1 & -2\\
19/11 & 4/11 & -1\\
 2/11 & 1/11 &  0
\end{bmatrix}$. Multiplicando esta matriz à esquerda de $M$, obtém-se:
\[
XM =
\begin{bmatrix}
    3 &    1 & -2\\
19/11 & 4/11 & -1\\
 2/11 & 1/11 &  0
\end{bmatrix}
\begin{bmatrix}
-1 &  2 & 3 \\
 2 & -4 & 5 \\
-1 &  1 & 7
\end{bmatrix}
=\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}.
\]
Isto quer dizer que a matrix $X$ que atua como inversa à direita de $A$ também é uma inversa à esquerda de $A$, pois ambos os produtos ($AX$ e $XA$) resultam na matriz identidade.


\item
\begin{enumerate}
\item Ao sortear 10 matrizes $7 \times 7$ \textit{aleatoriamente}, é bem provavel que \textbf{todas} as matrizes obtidas sejam inversíveis (execute o comando mais de 10 vezes se não estiver convencido).
\item Repetindo o experimento com matrizes quadradas de qualquer outro tamanho, há grandes chances de não encontrar uma única matriz que não seja inversível. De fato, ao sortear \textit{aleatoriamente} uma matriz quadrada, há \textbf{probabilidade zero} (não é só pequena, é zero!) de ser escolhida uma matriz não inversível. Elas são raras, mas pode se deparar com elas se estiver com sorte (ou se o sorteio não for realmente aleatório).

\item Sejam $A_2 =
\begin{bmatrix}
0 & 5 \\
0 & 0
\end{bmatrix}$, $A_3 =
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}$ e $A_4 =
\begin{bmatrix}
0 & -1 & 2 & 3 \\
0 &  0 & 1 & 5 \\
0 &  0 & 0 & 7 \\
0 &  0 & 0 & 0
\end{bmatrix}$. Então:
\begin{enumerate}
\item
\begin{align*}
A_2^2 & =
\begin{bmatrix}
0 & 5 \\
0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & 5 \\
0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 \\
0 & 0
\end{bmatrix}, \\
A_3^3 & =
\left(
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}
\right)
\cdot
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix} \\
& =
\begin{bmatrix}
0 & 0 & -10 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},\\
A_4^4 & =
\begin{bmatrix}
0 & -1 & 2 & 3 \\
0 &  0 & 1 & 5 \\
0 &  0 & 0 & 7 \\
0 &  0 & 0 & 0
\end{bmatrix}^2
\cdot
\begin{bmatrix}
0 & -1 & 2 & 3 \\
0 &  0 & 1 & 5 \\
0 &  0 & 0 & 7 \\
0 &  0 & 0 & 0
\end{bmatrix}^2
=
\begin{bmatrix}
0 & 0 & -1 & 9 \\
0 & 0 & 0 & 7 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}^2
=
\begin{bmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}.
\end{align*}

\item Com base nos exemplos anteriores, é natural suspeitar que a $n$-ésima potência de uma matriz triangular superior $n\times n$ qualquer, com zeros na diagonal, é sempre a matriz nula $n\times n$.
\item As matrizes triangulares superiores de tamanho $2 \times 2$, com zeros na diagonal, têm a forma $A_2 =
\begin{bmatrix}
0 & c\\
0 & 0
\end{bmatrix}$, em que $c$ pode ser qualquer escalar. Então:
\[
A_2^2 =
\begin{bmatrix}
0 & c\\
0 & 0
\end{bmatrix}
\begin{bmatrix}
0 & c\\
0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0\\
0 & 0
\end{bmatrix}
\]
Já no caso $3 \times 3$, tem-se $A_3=
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}$ e então:
\[
A_3^3 =
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}^2
\cdot
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & ac \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}.
\]
Mais geralmente, se $A = (a_{ij})$ for uma matriz triangular superior de tamanho $n \times n$ com diagonal nula, então as primeiras $i$ entradas da linha $i$ são todas nulas. Ao elevar $A$ ao quadrado, a matriz obtida terá as primeiras $i+1$ entradas da linha $i$ iguais a zero. Analogamente, ao calcular $A^3$, a matriz resultante terá $i+2$ entradas da linha $i$ igual a zero. Como a matriz tem $n$ colunas, procedendo desta maneira até obter $A^n$ o resultado final será uma matriz com zeros em todas as $n$ colunas de cada linha.
\[
\overset{A}{
\overbrace{
\begin{bmatrix}
\textbf{0} &     a_{12} & a_{13} & \ldots & a_{1n} \\
         0 & \textbf{0} & a_{23} & \ldots & a_{2n} \\
    \vdots &     \vdots & \ddots & \ddots & \vdots \\
         0 &          0 &      0 & \ddots & a_{n-1,n} \\
         0 &          0 &      0 & \ldots & \textbf{0}
\end{bmatrix}
}}
\rightarrow
\overset{A^2}{
\overbrace{
\begin{bmatrix}
         0 & \textbf{0} & a_{13} & \ldots & a_{1n} \\
         0 &          0 & \textbf{0} & \ldots & a_{2n} \\
    \vdots &     \vdots &     \ddots & \ddots & \vdots \\
         0 &          0 &          0 & \ddots & \textbf{0} \\
         0 &          0 &          0 & \ldots & 0
\end{bmatrix}
}}
%\rightarrow
\ldots \rightarrow
\overset{A^n}{
\overbrace{
\begin{bmatrix}
         0 &          0 &          0 & \ldots & \textbf{0} \\
         0 &          0 &          0 & \ldots & 0 \\
    \vdots &     \vdots &     \ddots & \ddots & \vdots \\
         0 &          0 &          0 & \ddots & 0 \\
         0 &          0 &          0 & \ldots & 0
\end{bmatrix}
}}
\]

O padrão acima também pode ser percebido ao calcular explicitamente as entradas dos produtos. Como a matriz $A$ é triangular superior e tem zeros na diagonal, tem-se $a_{ij} = 0$ sempre que $i \geq j$. Consequentemente, se $i \geq j-1$ a entrada $ij$ de $A^2$ é dada por
\begin{align*}
[A^2]_{ij}
  = [A \cdot A]_{ij}
& = (a_{i1} a_{1j}       + \ldots + a_{ii} a_{ij})
  + (a_{i,i+1} a_{i+1,j} + \ldots + a_{in} a_{nj}) \\
& = (0 a_{1j}       + \ldots + 0 a_{ij})
  + (a_{i,i+1} 0 + \ldots + a_{in} 0)
  = 0.
\end{align*}
Do mesmo modo, $[A^3]_{ij} = 0$ para $i \geq j-2$:
\begin{align*}
[A^3]_{ij}
  = [A^2 \cdot A]_{ij}
& = ([A^2]_{i1} a_{1j} + \ldots + [A^2]_{i,i+1} a_{i+1,j}) \\
& \quad + ([A^2]_{i,i+2} a_{i+2,j} + \ldots + [A^2]_{in} a_{nj}) \\
& = (0 a_{1j}       + \ldots + 0 a_{i+1,j})
  + ([A^2]_{i+2,j+1} 0 + \ldots + [A^2]_{in} 0)
  = 0.
\end{align*}
Procedendo da mesma maneira até a $n$-ésima potência de $A$, consegue-se todas as entradas iguais a zero.
\end{enumerate}
\end{enumerate}


\item Para que a matriz $T =
\begin{bmatrix}
-1 & 9 & 1 \\
-1 & t & 3 \\
-1 & 9 & t + 1
\end{bmatrix}$
seja inversível, sua forma escalonada reduzida por linhas deve ser a matriz identidade. Procedendo com a eliminação de Gauss-Jordan, seriam realizadas as seguintes operações elementares sobre as linhas:
\begin{align*}
\begin{bmatrix}
-1 & 9 & 1 \\
-1 & t & 3 \\
-1 & 9 & t + 1
\end{bmatrix}
\grstep{ -L_1 }
\begin{bmatrix}
1 & -9 & -1 \\
-1 & t & 3 \\
-1 & 9 & t + 1
\end{bmatrix}
\grstep{ L_2 + L_1 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & t-9 & 2 \\
-1 & 9 & t + 1
\end{bmatrix}
\grstep{ L_3 + L_1 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & t-9 & 2 \\
0 & 0 & t
\end{bmatrix}
\end{align*}
Neste ponto, para conseguir um pivô igual a $1$ na segunda coluna da segunda linha, seria necessária uma divisão da segunda linha por $t - 9$, e isso significa que se $t=9$ a matriz não será inversível. Além disso, no passo seguinte, será necessário dividir a terceira linha por $t$, de modo que para $t = 0$ a matriz também não será inversível. Supondo que $t \neq 0$ e $t \neq 9$, basta realizar mais algumas operações elementares e obtém-se a identidade:
\begin{align*}
\begin{bmatrix}
1 & -9 & -1 \\
0 & t-9 & 2 \\
0 & 0 & t
\end{bmatrix}
\grstep{ \frac{1}{t-9} L_2 }
&\begin{bmatrix}
1 & -9 & -1 \\
0 & 1 & \frac{2}{t-9} \\
0 & 0 & t
\end{bmatrix}
\grstep{ \frac{1}{t} L_3 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & 1 & \frac{2}{t-9} \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_2 -\frac{2}{t-9} L_3 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}\\
\grstep{ L_1 + L_3 }
&\begin{bmatrix}
1 & -9 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_1 + 9L_2 }
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}.
\end{align*}
Portanto, $T$ é inversível se, e somente se, $t \not \in \{0, 9\}$.
Aplicando a mesma sequência de operações elementares à matriz identidade, o resultado é a inversa de $T$:
0\begin{align*}
I
& \grstep{ -L_1 }
\begin{bmatrix}
-1 & 0 & 0 \\
 0 & 1 & 0 \\
 0 & 0 & 1
\end{bmatrix}
\grstep[ L_3 + L_1 ]{ L_2 + L_1 }
\begin{bmatrix}
-1 & 0 & 0 \\
-1 & 1 & 0 \\
-1 & 0 & 1
\end{bmatrix}
\grstep[\frac{1}{t} L_3]{ \frac{1}{t-9} L_2 }
\begin{bmatrix}
-1 & 0 & 0 \\
\frac{-1}{t-9} & \frac{1}{t-9} & 0 \\
\frac{-1}{t} & 0 & \frac{1}{t}
\end{bmatrix} \\
& \grstep{ L_2 -\frac{2}{t-9} L_3 }
\begin{bmatrix}
-1 & 0 & 0 \\
\frac{2-t}{(t-9)t} & \frac{1}{t-9} & \frac{-2}{(t-9)t} \\
\frac{-1}{t} & 0 & \frac{1}{t}
\end{bmatrix}
\grstep{ L_1 + L_3 }
\begin{bmatrix}
\frac{-t-1}{t} & 0 & \frac{1}{t} \\
\frac{2-t}{(t-9)t} & \frac{1}{t-9} & \frac{-2}{(t-9)t} \\
\frac{-1}{t} & 0 & \frac{1}{t}
\end{bmatrix}\\
&\grstep{ L_1 + 9L_2 }
\begin{bmatrix}
\dfrac{-t^2 - t + 27}{(t-9)t} & \dfrac{9}{t-9} & \dfrac{t-27}{(t-9)t}\\
\dfrac{2-t}{(t-9)t} & \dfrac{1}{t-9} & \dfrac{-2}{(t-9)t}\\
\dfrac{-1}{t} & 0 & \dfrac{1}{t}
\end{bmatrix} = T^{-1}.
\end{align*}


\item As operações elementares a seguir mostram que $N$ é equivalente por linhas à identidade, desde que seja possível dividir por $1-t$ e depois por $t(t+2)$. Isto significa que para $t \in\{ -2, 0, 1 \}$ a matriz $N$ não é inversível, pois apareceria uma linha nula em um dos passos da eliminação de Gauss-Jordan.
\begin{align*}
N= & \begin{bmatrix}
2-t & 0 & -4 \\
6 & 1-t & -15 \\
2 & 0 & -4-t
\end{bmatrix}
\grstep{ L_1 \swap L_3 }
\begin{bmatrix}
2 & 0 & -4-t \\
6 & 1-t & -15 \\
2-t & 0 & -4
\end{bmatrix}
\grstep{ \frac{1}{2} L_1 }
\begin{bmatrix}
1 & 0 & -2-\frac{t}{2} \\
6 & 1-t & -15 \\
2-t & 0 & -4
\end{bmatrix} \\
\grstep{ L_2 - 6 L_1 }
& \begin{bmatrix}
1 & 0 & -2-\frac{t}{2} \\
0 & 1-t & 3(t-1) \\
2-t & 0 & -4
\end{bmatrix}
\grstep{ L_3 - (2-t) L_1 }
\begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1-t & 3(t-1) \\
0 & 0 & -\frac{t(t+2)}{2}
\end{bmatrix}
\grstep{ \frac{1}{1-t} L_2 }
\begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1 & -3 \\
0 & 0 & -\frac{t(t+2)}{2}
\end{bmatrix}\\
\grstep{ -\frac{2}{t(t+2)} L_2 }
& \begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1 & -3 \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_2 + 3 L_3}
\begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_1 -\frac{4+t}{2} L_3}
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}.
\end{align*}
\end{enumerate}
\end{document}
