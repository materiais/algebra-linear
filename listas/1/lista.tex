\documentclass[12pt,a4paper]{article}
\usepackage{cmap} % Makes the PDF copiable. See http://tex.stackexchange.com/a/64198/25761
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{textcomp} % \degree
\usepackage{gensymb} % \degree
\usepackage[usenames,svgnames,dvipsnames]{xcolor}
\usepackage{hyperref}
\usepackage{multicol}
\usepackage{graphicx}
\usepackage[margin=2cm]{geometry}
\usepackage{systeme}

\hypersetup{
    colorlinks = true,
    allcolors = {blue}
}

\newcommand{\fixme}{{\color{red}(...)}}
\newcommand*\sen{\operatorname{sen}}

\newcommand*\R{\mathbb{R}}

\newcommand{\IconPc}{\includegraphics[width=1em]{computer.png}}
\newcommand{\IconCalc}{\includegraphics[width=1em]{calculator.png}}
\newcommand{\IconThink}{\includegraphics[width=1em]{pencil.png}}
\newcommand{\IconCheck}{\includegraphics[width=1em]{checkmark.png}}
\newcommand{\IconConcept}{\includegraphics[width=1em]{edit.png}}

\newlength{\SmileysLength}
\setlength{\SmileysLength}{\labelwidth}\addtolength{\SmileysLength}{\labelsep}

\newcommand{\calc}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCalc}%
   \hspace*{\SmileysLength}}
\newcommand{\software}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconPc}%
   \hspace*{\SmileysLength}}
\newcommand{\teoria}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconThink}%
   \hspace*{\SmileysLength}}
\newcommand{\conceito}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCheck}%
   \hspace*{\SmileysLength}}
\newcommand{\concept}{\hspace*{-\SmileysLength}\makebox[0pt][r]{\IconCheck}%
   \hspace*{\SmileysLength}}

% Loop Space / CC BY-SA-3.0 / https://tex.stackexchange.com/a/2238/25761
\newenvironment{amatrix}[1]{%
  \left[\begin{array}{@{}*{#1}{c}|c@{}}
}{%
  \end{array}\right]
}

% Loop Space / CC BY-SA-3.0 / https://tex.stackexchange.com/a/3164/25761
%--------grstep
% For denoting a Gauss' reduction step.
% Use as: \grstep{\rho_1+\rho_3} or \grstep[2\rho_5 \\ 3\rho_6]{\rho_1+\rho_3}
\newcommand{\grstep}[2][\relax]{%
   \ensuremath{\mathrel{
       {\mathop{\longrightarrow}\limits^{#2\mathstrut}_{
                                     \begin{subarray}{l} #1 \end{subarray}}}}}}
\newcommand{\swap}{\leftrightarrow}

\newcommand*\tipo{1ª Lista de Exercícios}
%\newcommand*\turma{...}
\newcommand*\disciplina{ALI0001}
\newcommand*\eu{Helder G. G. de Lima}
\newcommand*\data{\today}

\author{\eu}
\title{\tipo - \disciplina}
\date{}

\begin{document}

\begin{center}
\includegraphics[width=9.0cm]{marca.jpg} \\
\textbf{\tipo\ (\disciplina)} \\
Prof. \eu\footnote{
Este é um material de acesso livre distribuído sob os termos da licença \href{https://creativecommons.org/licenses/by-sa/4.0/deed.pt_BR}{Creative Commons Atribuição-CompartilhaIgual 4.0 Internacional}}
\end{center}

\section*{Legenda}
\begin{multicols}{4}
\begin{itemize}
\item[] \hspace*{\SmileysLength} \calc \hspace*{-\SmileysLength} Cálculos
\item[] \hspace*{\SmileysLength} \conceito \hspace*{-\SmileysLength} Conceitos
\item[] \hspace*{\SmileysLength} \teoria \hspace*{-\SmileysLength} Teoria
\item[] \hspace*{\SmileysLength} \software \hspace*{-\SmileysLength} Software
\end{itemize}
\end{multicols}

\section*{Questões}

\begin{enumerate}
\item \conceito
Exiba matrizes quadradas $A$ e $B$ de ordem $2 \times 2$ que exemplifiquem as situações a seguir. Compare com o que ocorreria se $A$ e $B$ fossem números reais.

\begin{enumerate}
\item É possível que $A^2 = B^2$ mesmo que $A \neq B$ e $A \neq -B$.
\item $(AB)^2 \neq A^2B^2$.
\item Pode ocorrer que $A^2 = 0$ apesar de $A \neq 0$.
\item Há casos em que $AB = 0$ ao mesmo tempo em que $0 \neq A \neq B \neq 0$.
\item Mesmo que $A \neq B$ pode existir uma matriz $P$ tal que $A = P^{-1}BP$.
%É possível que $A$ seja inversível e apesar disso $A^{-1}BA \neq B$.
\end{enumerate}

\item \calc Calcule, se existir, a inversa de cada uma das matrizes a seguir:
\begin{multicols}{3}
\begin{enumerate}
\item
 $D =
\begin{bmatrix}
1 & -2 & -3\\
1 & -3 & 2\\
-2 & 4 & 5
\end{bmatrix}$
\item $T =
\begin{bmatrix}
0 &  0 &  1 & 0\\
0 &  1 &  1 & 0\\
1 &  0 & -1 & 1\\
1 & -1 & -2 & 2
\end{bmatrix}$
\item
 $U =
\begin{bmatrix}
0 & 0 &  3 &  3\\
0 & 3 &  0 & -3\\
3 & 3 & -3 & -6\\
0 & 0 &  3 &  6
\end{bmatrix}$
\end{enumerate}
\end{multicols}

\item \conceito Seja $M = (m_{ij})$ a matriz de ordem $7 \times 7$ cujo termo geral é $m_{ij} = \begin{cases}
1, & \text{se}\ i \leq j,\\
0, & \text{se}\ i > j.
\end{cases}$

Utilize a definição do produto de matrizes para obter uma fórmula (em função de $i$ e $j$) para as seguintes entradas da matriz $C = M^2$:
\begin{multicols}{2}
\begin{enumerate}
\item $c_{1j}$, sendo $1 \leq j \leq 7$.
\item $c_{4j}$, quando $1 \leq j < 4$.
\item $c_{4j}$, quando $4 \leq j \leq 7$.
\item $c_{ij}$, quando $1 \leq j < i \leq 7$.
\item $c_{ij}$, quando $1 \leq i \leq j \leq 7$.
\end{enumerate}
\end{multicols}

\item \conceito Uma matriz $A$ é considerada \textbf{simétrica} se $A^T = A$ e \textbf{antissimétrica} se $A^T = -A$. Levando em conta as propriedades da transposição de matrizes, justifique as afirmações que forem verdadeiras e exiba um contra-exemplo para as falsas:
\begin{enumerate}
\item Todas as entradas da diagonal de uma matriz antissimétrica devem ser nulas.
\item Não existem matrizes simétricas que também sejam antissimétricas.
\item Toda matriz simétrica é antissimétrica.
\item Toda matriz antissimétrica é simétrica.
\item Se uma matriz não é simétrica, então ela é antissimétrica.
\end{enumerate}

\item \calc Encontre uma matriz triangular superior equivalente por linhas a cada matriz $P$ indicada a seguir, e utilize-as para calcular o determinante de $P$.
\begin{multicols}{2}
\begin{enumerate}
\item $P =
\begin{bmatrix}
 0 &  5 &  21\\
-3 & -7 & -13\\
 1 &  2 &   3 
\end{bmatrix}$
\item $P =
\begin{bmatrix}
0 & 6 & 0 & 10\\
0 & 3 & -1 & 5\\
0 & 9 & -3 & 14\\
5 & 0 & 0 & 1
\end{bmatrix}$
\item $P =
\begin{bmatrix}
 1 & 0 & 0 & 0 & 2 \\
 0 & 2 & 4 & 2 & 0 \\
 0 & 3 & 0 & 3 & 0 \\
 0 & 1 & 2 & -2 & 0 \\
 5 & 0 & 0 & 0 & 1 
\end{bmatrix}$
\end{enumerate}
\end{multicols}

\item \calc Supondo que a matriz $M =
\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}$
satisfaz $\det{M} = 9$, calcule $\begin{vmatrix}
a+c & a+b+c+d \\
2a & 2(a+b)
\end{vmatrix}$.

\item \conceito Dê exemplos de matrizes não nulas $A$ e $B$ de tamanho $n \times n$ (com $n \geq 2$) tais que:
\begin{multicols}{2}
\begin{enumerate}
\item $\det(A + B)    = \det(A) + \det(B)$
\item $\det(A + B) \neq \det(A) + \det(B)$
\item $\det(c A) = c \det(A)$, para algum $c \neq 0$
\item $\det(c A) \neq c \det(A)$, para algum $c \neq 0$
\end{enumerate}
\end{multicols}

\item \calc Verifique que as matrizes $P = \begin{bmatrix}
2 &  0 &  0 & 0\\
0 & -2 &  0 & 0\\
0 &  1 &  1 & 0\\
2 & -5 & -1 & 2
\end{bmatrix}$ e $Q = \begin{bmatrix}
 1 &  0 &  0 & -1\\
 0 &  1 & -1 &  2\\
 0 & -1 &  5 &  0\\
-1 &  2 &  0 &  7
\end{bmatrix}$ satisfazem:
\begin{enumerate}
\item $\det(PQ) = \det(P) \det(Q)$
\item $\det(QP) = \det(P) \det(Q)$
\item $\det(R^T) = \det(R)$, sendo $R = P + Q$
\item $\det(P^{-1}) = \dfrac{1}{\det(P)}$
\end{enumerate}

\item \calc Calcule o determinante das seguintes matrizes:
\begin{enumerate}
\item $Q = 
\begin{bmatrix}
 \frac{1}{12} & \frac{2}{3} & -\frac{1}{4} \\
 \frac{1}{3}  & \frac{1}{6} & -\frac{3}{4} \\
-\frac{1}{12} & \frac{1}{6} & 0
\end{bmatrix}$

\item $R = \begin{bmatrix}
\frac{\sqrt{3}}{2} & \frac{\sqrt{2}}{4} & -\frac{\sqrt{2}}{4} \\
-\frac{1}{2} & \frac{\sqrt{6}}{4} & -\frac{\sqrt{6}}{4} \\
0 & \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2}
\end{bmatrix}$

\item $T = D D^{T}$, sendo $D = 
\begin{bmatrix}
-1 & 1 & 1 &  0 \\
 2 & 2 & 0 & -1
\end{bmatrix}$

\item $U = D^{T} D$, sendo $D$ como no item anterior

\item $A = L U$, sendo $L =
\begin{bmatrix}
2 & 0 & 0 \\
1/2 & 3 & 0 \\
-5/4 & 9/2 & 1
\end{bmatrix}$ e $U = \begin{bmatrix}
-1 & 1/2 & 0 \\
 0 & 2 & -3/2 \\
 0 & 0 & 1
\end{bmatrix}$

\item $M = P Q P^{-1}$, sendo $P =
\begin{bmatrix}
   1 &  0 &  5 &  0\\
   0 &  1 &  0 &  3\\
   0 &  0 & -2 &  2\\
   0 &  0 &  0 &  1
\end{bmatrix}$ e $Q =
\begin{bmatrix}
 1 & -1 & 20 & -7 \\
 3 &  1 & 21 & -1 \\
 0 &  0 & -3 &  1 \\
-1 &  0 & -7 &  1
\end{bmatrix}$
\end{enumerate}

\item \calc Mostre que
\begin{enumerate}
\begin{multicols}{3}
\item 
$\begin{vmatrix}
x & y & z \\
u & v & 0 \\
w & 0 & 0
\end{vmatrix}
= -wvz$

\item 
$\begin{vmatrix}
a & b & c & d \\
e & f & g & 0\\
h & i & 0 & 0\\
j & 0 & 0 & 0
\end{vmatrix}
= jigd$

\item 
$\begin{vmatrix}
a & b & c & d & e \\
f & g & h & i & 0 \\
x & y & z & 0 & 0 \\
u & v & 0 & 0 & 0 \\
w & 0 & 0 & 0 & 0
\end{vmatrix}
= wvzie$
\end{multicols}
\end{enumerate}

\item \conceito Dê exemplos de matrizes $A$ e $B$ tais que
\begin{enumerate}
\item $A + B$ seja inversível, mas $A$ e $B$ não sejam
\item $A$ e $B$ sejam inversíveis, mas $A+B$ não seja
\item $A$, $B$ e $A+B$ sejam inversíveis
\end{enumerate}

\item \software Considere o sistema de equações lineares
\[
\systeme*{
2x - 3y = -4,
5x +  y = 7
}
\]
e utilize um software como o GeoGebra\footnote{\url{https://www.geogebra.org/download/}} para:
\begin{enumerate}
\item Plotar o conjunto $A$ formado pelos pontos $(x, y)$ cujas coordenadas satisfazem a primeira equação e o conjunto $B$ dos que verificam a segunda equação.

\textbf{Dica}: Não é preciso um comando especial para representar equações polinomiais no GeoGebra. Basta digitá-las diretamente (mesmo se forem como \texttt{5xy\^{}2+2y\^{}3x\^{}2=1}).
\item Alterar algumas vezes os números do segundo membro, e perceber o tipo de mudança que ocorre na representação gráfica de $A$ e $B$.
\item Verificar se com alguma escolha de valores os conjuntos se intersectam. Parece ser possível que isso não aconteça dependendo dos valores escolhidos?

\textbf{Dica}: O comando \texttt{Interseção[p, q]} gera a interseção dos objetos \texttt{p} e \texttt{q}.
\end{enumerate}

\item \software Repita o exercício anterior para o seguinte sistema, em uma janela de visualização 3D:
\[
\systeme*{
 x - y + z = 1,
2x + y + z = 4,
 x + y + 5z= 7
}
\]

\item Considere os seguintes sistemas lineares nas variáveis $x,y \in \R$:
\begin{multicols}{2}
\begin{itemize}
\item[] \begin{equation}
\begin{cases}
 x + 2y &= 6 \\
 2x - c y &= 0
\end{cases}\end{equation}

\item[] \begin{equation}
\systeme*{
   x + 2y = 6,
-c x +  y = 1 - 4c
} \end{equation}
\end{itemize}
\end{multicols}
\begin{enumerate}
\item \calc Determinar para quais valores de $c$ os sistemas lineares têm uma, nenhuma ou infinitas soluções. 
\item \software Obtenha as mesmas conclusões sobre $c$ experimentalmente, usando o GeoGebra. \textbf{Dica}: defina por exemplo \texttt{c=10} e use o botão direito do mouse para tornar o número visível como um ``controle deslizante'' e mova-o para ver o efeito deste parâmetro.
\end{enumerate}


\item \calc Determine para que valores de $t$ o sistema linear $(A - tI)X = 0$ possui mais de uma solução, sendo $I$ a matriz identidade, $A$ a matriz definida nos casos a seguir, $(A - tI)$ a matriz de coeficientes do sistema, e $0$ uma matriz coluna de ordem apropriada.
\begin{multicols}{3}
\begin{enumerate}
\item $A = \begin{bmatrix}
0 & 3 \\
1 & 2
\end{bmatrix}$
\item $A = \begin{bmatrix}
0 & 0 &  0 \\
1 & 0 & 20 \\
0 & 1 & -1
\end{bmatrix}$
\item $A = \begin{bmatrix}
0 & 0 & 0 &  0 \\
1 & 0 & 0 &  0 \\
0 & 1 & 0 & 3 \\
0 & 0 & 1 & -2
\end{bmatrix}$
\end{enumerate}
\end{multicols}


\item \calc Obtenha a forma escalonada reduzida por linhas da matriz de coeficientes de cada um dos sistemas lineares a seguir, e partir dela determine as soluções dos sistemas:
\begin{multicols}{2}
\begin{enumerate}
\item $\left\{
\begin{aligned}
5s & {}-{} &  5\pi t & {}={} & -5\pi^2\\
-s & {}+{} & (\pi+3)t & {}={} & \pi(\pi+6)
\end{aligned}
\right.%, \text{ sendo } s,t \in \R
$

\item $\systeme{
4x_1+4x_2 = 16,
5x_2 -15x_4=2,
2x_1+2x_2+x_3=12,
-x_2+8x_4=3/5
}%, \text{ sendo } x_i \in \Q
$

\item $\systeme{
          3x_1-12x_2 -6x_3              +9x_5=-21,
          -x_1 +4x_2 +2x_3              -3x_5=7,
\frac{1}{2}x_1 -2x_2  -x_3+x_4-\frac{3}{2}x_5=-\frac{5}{2},
         -7x_1+28x_2+15x_3             -23x_5=53
}%, \text{ sendo } x_i \in \R
$

\item $\systeme{
     b+6c= 6,
  a+6b-5c=-3,
3a+20b-3c= 1
}%, \text{ sendo } a, b, c \in \R
$
\end{enumerate}
\end{multicols}

\item \calc Utilize matrizes inversas para resolver os sistemas anteriores, quando for possível.

\item \calc Resolva os seguintes sistemas lineares sobre $\R$, usando matrizes inversas:
\begin{multicols}{3}
\begin{enumerate}
\item $\systeme{
   -y+5z=2,
 x+2y+3z=7,
2x+4y+5z=13
}$
\item $\systeme{
   -v+5w=0,
 u+2v+3w=0,
2u+4v+5w=0
}$
\item $\systeme{
   -q+5r=-2,
 p+2q+3r=3,
2p+4q+5r=1
}$
\end{enumerate}
\end{multicols}

\item \conceito Se $A$ é uma matriz $p \times q$, $B$ uma matriz $q \times r$ e $C$ uma matriz $r \times q$, qual é o tamanho da matriz $M = (B + C^T) ((AB)^T + CA^T)$?

\item \teoria Se $X$ é uma matriz $m \times n$, para que valores de $m$ e $n$ as operações a seguir fazem sentido? 
Quais os tamanhos das matrizes obtidas? Quais delas são simétricas? Justifique.
\begin{multicols}{5}
\begin{enumerate}
\item $X X^T$
\item $X^T X$
\item $X + X^T$
\item $X^T + X$
\item $X - X^T$
\end{enumerate}
\end{multicols}

\item \teoria Seja $M = \begin{bmatrix}a & b \\ c & d\end{bmatrix} \in M_{2 \times 2} (\R)$ a matriz associada a um sistema linear homogêneo. Utilize a eliminação de Gauss-Jordan para provar que se $ad-bc \neq 0$ então o sistema possui somente a solução trivial.

\item \calc Suponha que $M = \begin{bmatrix} -1 & 2 & 3 \\ 2 &-4 & 5 \\ -1 &1 &7\end{bmatrix}$ e $X = \begin{bmatrix} a & b & c \\ d & e& f \\ g &h &i\end{bmatrix} \in M_{3 \times 3}(\R)$ são tais que $M X = I_{3 \times 3}$. Determine $X$, por meio da comparação das entradas de $MX$ e $I$, e depois calcule $XM$.

\newpage
\item Em um software de computação numérica (GNU Octave\footnote{\url{https://www.gnu.org/software/octave/download.html}}, o Scilab\footnote{\url{http://www.scilab.org/download/latest}}, MatLab, etc):
\begin{enumerate}
\item \software Sortear ao acaso 10 matrizes de ordem $7\times 7$ e verificar quantas delas são inversíveis. \textbf{Dica}: o comando \texttt{rand(m,n)} gera aleatoriamente uma matriz de ordem $m \times n$, e o comando \texttt{det(A)} calcula o determinante da matriz $A$.
\item \software Repetir o experimento anterior com matrizes quadradas de algum outro tamanho. O que ocorre com a maioria das matrizes em cada uma das dimensões consideradas?
\item Escolher matrizes triangulares superiores $A_2$, $A_3$ e $A_4$ de ordens $2 \times 2$, $3 \times 3$ e $4 \times 4$ respectivamente, todas com zeros na diagonal e então:
\begin{enumerate}
\item \software Calcular as potências $A_2^2$, $A_3^3$ e $A_4^4$.
\item \teoria Com base nos resultados obtidos, formule uma conjectura a respeito da $n$-ésima potência das matrizes triangulares superiores $n\times n$, com zeros na diagonal.
\item \teoria Prove que o seu palpite é realmente válido para \textbf{qualquer} matriz nas condições acima (pelo menos nos casos $2 \times 2$ e $3 \times 3$). 
\end{enumerate}
\end{enumerate}

\item \calc Para que valor(es) de $t \in \R$ a matriz $T = \begin{bmatrix} -1 & 9 & 1 \\ -1 &t & 3 \\ -1 & 9 &t+1\end{bmatrix}$ é inversível? Qual é a inversa?

\item \calc Existe algum $t \in \R$ para o qual $N = \begin{bmatrix} 2-t & 0 & -4 \\ 6 & 1-t & -15 \\ 2 & 0 & -4-t\end{bmatrix} \in M_{3\times 3}(\R)$ não é inversível?

\item \conceito Justifique as afirmações verdadeiras e exiba um contra-exemplo para as demais:

\begin{enumerate}
\item A matriz nula é uma matriz na forma escalonada reduzida por linhas.
\item A matriz identidade $4 \times 4$ está na forma escalonada reduzida por linhas.
%\item Toda matriz escalonada por linhas está na forma escalonada reduzida.
\item Se uma matriz triangular superior é simétrica então ela é uma matriz diagonal.
\item Se $U$ e $V$ são matrizes diagonais, então $UV = VU$.
\item Se $A$ é uma matriz antissimétrica, isto é, se $A^T = -A$, então $A^T$ é antissimétrica.
\item Se $A$ é uma matriz $n \times n$ antissimétrica, então sua diagonal é igual a zero.
\item Nenhuma matriz $A$ $n \times n$ pode ser simétrica e antissimétrica simultaneamente.
\end{enumerate}

\item \calc Quantas matrizes diagonais $D$ de ordem $2 \times 2$ satisfazem $D^2 = I$, isto é, quantas matrizes diagonais são ``raizes quadradas'' da matriz identidade de ordem 2? E se $D$ for $3 \times 3$?
\item \calc Encontre todas as matrizes diagonais $D$ de ordem $3 \times 3$ tais que $D^2 - 7D + 10I = 0$.


\item \teoria Mostre que se $S$ é uma matriz simétrica então $S^2$ também é simétrica. Decida se vale o mesmo para $S^n$, qualquer que seja $n \in \mathbb{N}$, e explique sua conclusão.
\item \teoria Se $M$ é uma matriz quadrada $n \times n$, a soma das entradas da diagonal de $M$ é chamada de \textbf{traço} de $M$, e denotada por $tr(M) = m_{11} + m_{22} + \ldots + m_{nn}$. Explique por que são válidas as seguintes afirmações, para quaisquer matrizes $A$ e $B$ e todo $c \in \R$:
\begin{enumerate}
\item $tr(A+B) = tr(A)+tr(B)$
\item $tr(c \cdot A) = c \cdot tr(A)$
\item $tr(A^T) = tr(A)$
\end{enumerate}
\end{enumerate}



\newpage
\section*{Respostas}
\begin{enumerate}
\item Em todos os itens há uma infinidade de matrizes que exemplificam as afirmações feitas. Seguem alguns exemplos:
\begin{enumerate}
\item Para $A =
\begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}$ e $B =
\begin{bmatrix}
-1 & 0 \\
 0 & 1
\end{bmatrix}$ é verdade que $A^2 = I = B^2$, mas $A \neq B$ e $A \neq -B$.
\item Se $A =
\begin{bmatrix}
1 & 0 \\
0 & 0
\end{bmatrix}$ e $B =
\begin{bmatrix}
0 & 2 \\
2 & 2
\end{bmatrix}$
então $(AB)^2 = \begin{bmatrix}
0 & 0 \\
0 & 0
\end{bmatrix}$ mas $A^2B^2 = \begin{bmatrix}
4 & 4 \\
0 & 0
\end{bmatrix}$.
\item Toda matriz $A =
\begin{bmatrix}
0 & k \\
0 & 0
\end{bmatrix}$
satisfaz $C^2=0$, até mesmo quando $k \neq 0$ (e então $A \neq 0$).
\item
Se $A =
\begin{bmatrix}
1 & 0 \\
0 & 0
\end{bmatrix}$ e $B =
\begin{bmatrix}
0 & 0 \\
0 & 1
\end{bmatrix}$
então $AB = \begin{bmatrix}
0 & 0 \\
0 & 0
\end{bmatrix}$ mas $0 \neq A \neq B \neq 0$.

\item Se $P =
\begin{bmatrix}
1 & 2 \\
0 & -1
\end{bmatrix}$ e $B =
\begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}$
então $A = P ^{-1}BP = \begin{bmatrix}
7 & 4 \\
-3 & -2
\end{bmatrix}$ é diferente de $B$.
\end{enumerate}

\item \begin{enumerate}
\item
$D^{-1} = \begin{bmatrix}
-23& -2& -13\\
 -9& -1& -5\\
 -2&  0& -1
\end{bmatrix}$
\item
$T^{-1} = \begin{bmatrix}
 1& -1&  2& -1\\
-1&  1&  0&  0\\
 1&  0&  0&  0\\
 0&  1& -1&  1
\end{bmatrix}$
\item
$U^{-1} = \begin{bmatrix}
 1/3& -1/3& 1/3&    0\\
-1/3&  1/3&   0&  1/3\\
 2/3&    0&   0& -1/3\\
-1/3&    0&   0&  1/3
\end{bmatrix}$
\end{enumerate}

\item \begin{enumerate}
\item
As entradas da primeira linha são dadas por $c_{1j} = j$ pois, por definição,
\begin{align*}
c_{1j} & = \underbrace{m_{11}m_{1j} + m_{12}m_{2j} + \ldots + m_{1j}m_{jj}}_{j\ \text{parcelas}} + \underbrace{\ldots + m_{17}m_{7j}}_{7-j\ \text{parcelas}} \\
       & =\underbrace{1 + 1 + \ldots 1}_{j\ \text{vezes}} + \underbrace{0 + \ldots 0}_{7-j\ \text{vezes}} = j.
\end{align*}

\item
Se $1 \leq j < 4$, então
$c_{4j} = 0$ pois
\begin{align*}
c_{4j} & = m_{41}m_{1j} + m_{42}m_{2j} + m_{43}m_{3j} + m_{44}m_{4j} + \ldots + m_{47}m_{7j} \\
       & = 0 m_{1j} + 0 m_{2j} + 0 m_{3j} + 1 m_{4j} + \ldots + 1m_{7j} \\
       & = m_{4j} + \ldots + m_{7j} \\
       & = 0 + \ldots + 0 = 0.
\end{align*}

\item
Se $4 \leq j \leq 7$, então $c_{4j} = j - i + 1$.
\item
Se $1 \leq j < i \leq 7$, então $c_{ij} = 0$.
\item
Se $1 \leq i \leq j \leq 7$, então $c_{ij} = j - i + 1$.
\end{enumerate}

\item \begin{enumerate}
\item
\textbf{Verdadeira}, pois dada uma matriz antissimétrica $A \in M_{n \times n}(\R)$, tem-se $[A]_{ij} = [A^T]_{ji} = -[A]_{ji}$. Em particular, se $i = j$, vale $[A]_{ii} = -[A]_{ii}$, o que implica que  $2[A]_{ii} = 0$, isto é,  $[A]_{ii} = 0$. Assim, todas as entradas da diagonal de $A$ são nulas.
\item
\textbf{Falsa}, pois a matriz nula $0 \in M_{n \times n}(\R)$ é simétrica e antissimétrica simultaneamente.
\item
\textbf{Falsa}, pois $C = \begin{bmatrix}
1 & 2 \\ 2 & 3
\end{bmatrix}$ é simétrica mas não é antissimétrica.
\item
\textbf{Falsa}, pois $D = \begin{bmatrix}
0 & 2 \\ -2 & 0
\end{bmatrix}$ é antissimétrica mas não é simétrica.
\item
\textbf{Falsa}, pois $E = \begin{bmatrix}
1 & 2 \\ 3 & 4
\end{bmatrix}$ não é uma matriz simétrica mas não é antissimétrica.
\end{enumerate}

\item \begin{enumerate}
\item
$\det{P} =
-
\begin{vmatrix}
0 & 5 & 21\\
3 & 7 & 13\\
1 & 2 &  3 
\end{vmatrix}
=
\begin{vmatrix}
1 & 2 &  3\\ 
3 & 7 & 13\\
0 & 5 & 21
\end{vmatrix}
=
\begin{vmatrix}
1 & 2 &  3\\ 
0 & 1 &  4\\
0 & 5 & 21
\end{vmatrix}
=
\begin{vmatrix}
1 & 2 & 3\\ 
0 & 1 & 4\\
0 & 0 & 1
\end{vmatrix}
= 1$

\item
$\det{P}
%=
%\begin{vmatrix}
%0 & 6 & 0 & 10\\
%0 & 3 & -1 & 5\\
%0 & 9 & -3 & 14\\
%5 & 0 & 0 & 1
%\end{vmatrix}
=
-
\begin{vmatrix}
5 & 0 & 0 & 1\\
0 & 3 & -1 & 5\\
0 & 9 & -3 & 14\\
0 & 6 & 0 & 10
\end{vmatrix}
=
-
\begin{vmatrix}
5 & 0 & 0 & 1\\
0 & 3 & -1 & 5\\
0 & 0 & 0 & -1\\
0 & 0 & 2 & 0
\end{vmatrix}
=
\begin{vmatrix}
5 & 0 & 0 & 1\\
0 & 3 & -1 & 5\\
0 & 0 & 2 & 0\\
0 & 0 & 0 & -1
\end{vmatrix}
= -30$

\item
\begin{align*}
\det{P}
& =
2 \cdot 3 \cdot
\begin{vmatrix}
 1 & 0 & 0 & 0 & 2 \\
 0 & 1 & 2 & 1 & 0 \\
 0 & 1 & 0 & 1 & 0 \\
 0 & 1 & 2 & -2 & 0 \\
 5 & 0 & 0 & 0 & 1 
\end{vmatrix}
=
6
\begin{vmatrix}
 1 & 0 & 0 & 0 & 2 \\
 0 & 1 & 2 & 1 & 0 \\
 0 & 1 & 0 & 1 & 0 \\
 0 & 1 & 2 & -2 & 0 \\
 0 & 0 & 0 & 0 & -9 
\end{vmatrix}
=
6
\begin{vmatrix}
 1 & 0 & 0 & 0 & 2 \\
 0 & 1 & 2 & 1 & 0 \\
 0 & 0 & -2 & 0 & 0 \\
 0 & 0 & 0 & -3 & 0 \\
 0 & 0 & 0 & 0 & -9 
\end{vmatrix} \\
& =
6 \cdot 1 \cdot 1 \cdot (-2) \cdot (-3) \cdot (-9)
= -324
\end{align*}
\end{enumerate}

\item Usando as propriedades dos determinantes relacionadas ao uso de operações elementares sobre as linhas e colunas da matriz $S$, resulta que:
\begin{align*}
\det{S}
& = \begin{vmatrix}
a+c & a+b+c+d \\
2a & 2(a+b)
\end{vmatrix}
= 2
\begin{vmatrix}
a+c & a+b+c+d \\
a & a+b
\end{vmatrix}
= 2
\begin{vmatrix}
a+c & b+d \\
a & b
\end{vmatrix} \\
& = 2
\begin{vmatrix}
c & d \\
a & b
\end{vmatrix}
= -2
\begin{vmatrix}
a & b \\
c & d
\end{vmatrix}
= -2 \det{M}
=-18.
\end{align*}

\item \begin{enumerate}
\item Considere $A = I \in M_{3 \times 3}(\R)$ e $B = -I \in M_{3 \times 3}(\R)$. Então $\det(A+B) = \det(0) = 0 = 1 + (-1) = \det(A) + \det(B)$.
\item Considere $A = B = I \in M_{2 \times 2}(\R)$. Então $\det(A) = \det(B) = 1$ e $\det(A+B) = \det(2I) = 4$, enquanto que $\det(A) + \det(B) = 1 + 1 = 2$.
\item Sabe-se que para $A \in M_{n \times n}(\R)$, vale $\det(cA) = c^n\det(A)$. Deste modo, $\det(cA) = c \det(A)$ se, e somente se, $c^n\det(A) = c\det(A)$. Ou seja, pode-se escolher qualquer matriz que não seja inversível, e o resultado será \[c^n\det(A) = c^n 0 = 0 = c 0 = c\det(A).\] Outra opção é escolher $c = 1$ e qualquer matriz inversível $A$.
\item Seguindo o raciocínio do item anterior, basta escolher uma matriz $A$ inversível e qualquer $c \in \R$ tal que $c^n \neq c$, ou seja, $c \neq 1$ e $c \neq 0$.
\end{enumerate}

\item \begin{enumerate}
\item $\det(PQ) = -32 = (-8) \cdot 4 = \det(P) \cdot \det(Q)$
\item $\det(QP) = -32 = (-8) \cdot 4 = \det(P) \cdot \det(Q)$
\item $R = P+Q = \begin{bmatrix}
3 &  0 &  0 & -1\\
0 & -1 & -1 &  2\\
0 &  0 &  6 &  0\\
1 & -3 & -1 &  9
\end{bmatrix}$ e $\det(R)^T = -60 = \det(R)$.
\item $\displaystyle \det(P^{-1}) = -1/8 = \frac{1}{-8} = \frac{1}{\det(P)} = \det(P)^{-1}$
\end{enumerate}
\item 
\begin{enumerate}
\item $\det(Q) = \frac{5}{144}$
\item $\det(R) = 1$
\item $T = DD^T = \begin{bmatrix}
3 & 0\\
0 & 9
\end{bmatrix}$ e $\det(T) = 27$
\item $U = D^TD = \begin{bmatrix}
 5 &  3 & -1 & -2\\
 3 &  5 &  1 & -2\\
-1 &  1 &  1 &  0\\
-2 & -2 &  0 &  1
\end{bmatrix}$ e $\det(T) = 0$
\item $A = LU = \begin{bmatrix}
          -2 &            1 &             0 \\
-\frac{1}{2} & \frac{25}{4} &  -\frac{9}{2} \\
 \frac{5}{4} & \frac{67}{8} & -\frac{23}{4}
\end{bmatrix}$ e $\det(T) = \det(L) \det(U) = (2 \cdot 3 \cdot 1) \cdot (-1 \cdot 2 \cdot 1)= -12$
\item $M = \begin{bmatrix}
 1 & -1 &  0 &  1\\
 0 &  1 &  0 & -1\\
-2 &  0 & -1 &  2\\
-1 &  0 &  1 & -1
\end{bmatrix}$ e $\det(M) = \det(P)\det(Q)\det(P^{-1}) = \frac{\det(P)\det(Q)}{\det(P)} = \det(Q) = -1$
\end{enumerate}

\item \begin{enumerate}
\item 
$\begin{vmatrix}
\textbf{x} & \textbf{y} & \textbf{z} \\
u & v & 0 \\
\textbf{w} & \textbf{0} & \textbf{0}
\end{vmatrix}
= -
\begin{vmatrix}
\textbf{w} & 0 & 0 \\
u & \textbf{v} & 0 \\
x & y & \textbf{z}
\end{vmatrix}
= -wvz$, pois o determinante de matrizes triangulares inferiores é o produto das entradas que aparecem na diagonal.

\item 
$\begin{vmatrix}
\textbf{a} & \textbf{b} & \textbf{c} & \textbf{d} \\
e & f & g & 0\\
h & i & 0 & 0\\
\textbf{j} & \textbf{0} & \textbf{0} & \textbf{0}
\end{vmatrix}
= -
\begin{vmatrix}
j & 0 & 0 & 0\\
\textbf{e} & \textbf{f} & \textbf{g} & \textbf{0}\\
\textbf{h} & \textbf{i} & \textbf{0} & \textbf{0}\\
a & b & c & d
\end{vmatrix}
=
\begin{vmatrix}
\textbf{j} & 0 & 0 & 0\\
h & \textbf{i} & 0 & 0\\
e & f & \textbf{g} & 0\\
a & b & c & \textbf{d}
\end{vmatrix}
= jigd$

\item 
$\begin{vmatrix}
\textbf{a} & \textbf{b} & \textbf{c} & \textbf{d} & \textbf{e} \\
f & g & h & i & 0 \\
x & y & z & 0 & 0 \\
u & v & 0 & 0 & 0 \\
\textbf{w} & \textbf{0} & \textbf{0} & \textbf{0} & \textbf{0}
\end{vmatrix}
= -
\begin{vmatrix}
w & 0 & 0 & 0 & 0 \\
\textbf{f} & \textbf{g} & \textbf{h} & \textbf{i} & \textbf{0} \\
x & y & z & 0 & 0 \\
\textbf{u} & \textbf{v} & \textbf{0} & \textbf{0} & \textbf{0} \\
a & b & c & d & e
\end{vmatrix}
=
\begin{vmatrix}
\textbf{w} & 0 & 0 & 0 & 0 \\
u & \textbf{v} & 0 & 0 & 0 \\
x & y & \textbf{z} & 0 & 0 \\
f & g & h & \textbf{i} & 0 \\
a & b & c & d & \textbf{e}
\end{vmatrix}
= wvzie$
\end{enumerate}

\item \begin{enumerate}
\item Se
$A = \begin{bmatrix}
1 & 0 \\
0 & 0
\end{bmatrix}$
e 
$B = \begin{bmatrix}
0 & 0 \\
0 & 1
\end{bmatrix}$, então
$A + B
= \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix} = I$, que é inversível. Porém, $A$ e $B$ não são inversíveis, já que possuem uma coluna de zeros.

\item Se
$A = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}$
e 
$B = \begin{bmatrix}
0 & 1 \\
1 & 0
\end{bmatrix}$, então
$A + B
= \begin{bmatrix}
1 & 1 \\
1 & 1
\end{bmatrix}$ não é inversível, pois $AX = 0$ tem uma solução não nula $X = \begin{bmatrix}
1\\-1
\end{bmatrix}$. Porém, $A = A^{-1}$ e $B = B^{-1}$ são inversíveis.

\item Se
$A = B = \begin{bmatrix}
1 & 0 \\
0 & 1
\end{bmatrix}$, então
$A + B
= \begin{bmatrix}
2 & 0 \\
0 & 2
\end{bmatrix}$ e as matrizes $A$, $B$ e $A+B$ são inversíveis, sendo  $A^{-1} = B^{-1} = I$ e $(A+B)^{-1} = (2I)^{-1} = \frac{1}{2} I$.
\end{enumerate}

\item \begin{enumerate}
\item Digite \texttt{2x-3y=-4} para que o GeoGebra mostre a reta formada pelos pontos que satisfazem a primeira equação, e \texttt{5x+y=7} para representar a segunda reta.
\item Ao trocar o $-4$ por um número maior, a reta correspondente se desloca para baixo, mantendo-se paralela à reta original. Ao diminuir este valor, a reta se desloca paralelamente para cima. Na segunda equação, a troca de $7$ por um número maior resulta em um deslocamento para a direita, e a diminuição deste valor desloca a reta para a esquerda.

\item As retas, que inicialmente se intersectam em $(1,2)$, têm sempre um ponto em comum, independentemente dos valores atribuídos ao segundo membro das equações. Isso reflete o fato de que as duas equações correspondem a retas que não são paralelas entre si, e sua direção permanece inalterada mesmo quando o segundo membro é modificado.
\end{enumerate}


\item 
\begin{enumerate}
\item Digite \texttt{x-y+z=1} para que o GeoGebra mostre o plano formado pelos pontos $(x,y,z)$ que satisfazem a primeira equação, e então \texttt{2x+y+z=4} e \texttt{x+y+5z=7} para representar os planos correspondentes às demais equações.
\item A trocar os valores do segundo membro de cada equação, o plano correspondente desloca-se no espaço mantendo-se paralelo à sua posição original.

\item Como os planos se intersectam inicialmente no ponto $(1,1,1)$, e sempre permanecem paralelos às suas posições iniciais, continua existindo um único ponto de interseção, quaisquer que sejam os valores do segundo membro do sistema.
\end{enumerate}

\item
\begin{enumerate}
\item
\begin{enumerate}
\item A matriz aumentada associada ao primeiro sistema pode ser levada à sua forma escalonada reduzida por linhas por meio das seguintes operações elementares:
\[
\begin{amatrix}{2}
1 & 2 & 6 \\
2 & -c & 0
\end{amatrix}
\grstep{ L_2 - 2 L_1 }
\begin{amatrix}{2}
1 & 2 & 6 \\
0 & -c-4 & -12
\end{amatrix}
\grstep{ \frac{-1}{c+4} L_2 }
\begin{amatrix}{2}
1 & 2 & 6 \\
0 & 1 & \frac{12}{c+4}
\end{amatrix}
\grstep{ L_1 - 2 L_2 }
\begin{amatrix}{2}
1 & 0 & \frac{6c}{c+4} \\
0 & 1 & \frac{12}{c+4}
\end{amatrix}
\]

Se $c = -4$ a segunda operação deixa de ser possível, e o sistema não tem solução. Por outro lado, se $c \neq -4$, todos os passos podem ser realizados e conclui-se que o sistema é possível e determinado, tendo como única solução o ponto $\left(\frac{6c}{c+4}, \frac{12}{c+4}\right)$.
\item A matriz aumentada associada ao segundo sistema pode ser levada à sua forma escalonada reduzida por linhas por meio das seguintes operações elementares:
\begin{align*}
\begin{amatrix}{2}
1 & 2 & 6 \\
-c & 1 & 1-4c
\end{amatrix}
\grstep{ L_2 + c L_1 }
\begin{amatrix}{2}
1 & 2 & 6 \\
0 & 1+2c & 1+2c
\end{amatrix}
&
\grstep{ \frac{1}{1+2c} L_2 }
\begin{amatrix}{2}
1 & 2 & 6 \\
0 & 1 & 1
\end{amatrix}
\grstep{ L_1 - 2 L_2 }
\begin{amatrix}{2}
1 & 0 & 4 \\
0 & 1 & 1
\end{amatrix}
\end{align*}

Desta vez, se $c = -1/2$ a segunda linha zera após a primeira operação elementar, e o sistema tem mais de uma solução. De fato, o escalonamento mostra que o sistema original é equivalente a um sistema formado pela primeira equação e por uma equação do tipo $0=0$, que não impõe qualquer restrição sobre os valores de $x$ e $y$. Assim, todo par da forma $(6-2y, y)$, com $y \in \R$, é solução deste sistema possível e indeterminado.

Por outro lado, nos casos em que $c \neq -1/2$, os três passos da eliminação de Gauss-Jordan podem ser realizados, e a conclusão é de que o sistema possui como única solução o ponto $(4,1)$, sendo então possível e determinado.
\end{enumerate}

\item \begin{enumerate}
\item Geometricamente, nota-se que conforme o valor de $c$ vai se aproximando de $c=-4$ a reta que corresponde à segunda equação gira em torno da origem até ficar paralela à reta da primeira equação. Quando isso ocorre, não há um ponto de interseção. Nos demais casos, as retas se intersectam em um único ponto.
\item Geometricamente, ao variar o valor de $c$, uma das retas gira em torno do ponto $(4,1)$, em que elas se intersectam, e em um caso específico (quando $c=-1/2$) as duas retas coincidem, fazendo com que todos os seus pontos sejam pontos de interseção.
\end{enumerate}
\end{enumerate}

\item O sistema $(A - tI)X = 0$ possui mais de uma solução se, e somente se, a matriz $(A - tI)$ não for inversível, isto é, se $\det(A - tI) = 0$. Em cada um dos casos, esta condição resultará em uma equação polinomial na variável $t$, cujas soluções são dadas a seguir:
\begin{enumerate}
\item $t=3$ ou $t=-1$
\item $t=-5$ ou $t=0$ ou $t=4$
\item $t=-3$ ou $t=0$ ou $t=1$
\end{enumerate}

\item \begin{enumerate}
\item A matriz aumentada associada ao sistema dado é $A = \begin{amatrix}{2}
 5 & -5\pi & -5\pi^2 \\
-1 & \pi+3 & \pi(\pi + 6)
\end{amatrix}$
e sua forma escalonada reduzida é obtida por meio das seguintes operações elementares sobre as linhas:
\begin{align*}
A
&
\grstep{ \frac{1}{5} L_1 }
\begin{amatrix}{2}
 1 & -\pi & -\pi^2 \\
-1 & \pi+3 & \pi(\pi + 6)
\end{amatrix}
\grstep{ L_2 + L_1 }
\begin{amatrix}{2}
 1 & -\pi & -\pi^2 \\
 0 &    3 & 6\pi
\end{amatrix} \\
&
\grstep{ \frac{1}{3} L_2 }
\begin{amatrix}{2}
 1 & -\pi & -\pi^2 \\
 0 &    1 & 2\pi
\end{amatrix}
\grstep{ L_1 + \pi L_2 }
\begin{amatrix}{2}
 1 & 0 & \pi^2 \\
 0 & 1 & 2\pi
\end{amatrix}
\end{align*}
Esta última matriz está associada às equações
\[
\left\{
\begin{aligned}
s & = \pi^2 \\
t & = 2\pi
\end{aligned}
\right.,
\]
e, portanto, $S = \{ ( \pi^2, 2\pi ) \}$ é o conjunto das soluções do sistema proposto.

\item A redução à forma escalonada reduzida da matriz associada ao sistema é obtida através das seguintes operações elementares:
\begin{align*}
\begin{amatrix}{4}
4 &  4 & 0 &   0 & 16 \\
0 &  5 & 0 & -15 & 2 \\
2 &  2 & 1 &   0 & 12 \\
0 & -1 & 0 &   8 & 3/5
\end{amatrix}
&
\grstep{ \frac{1}{4} L_1 }
\begin{amatrix}{4}
1 &  1 & 0 &   0 & 4 \\
0 &  5 & 0 & -15 & 2 \\
2 &  2 & 1 &   0 & 12 \\
0 & -1 & 0 &   8 & 3/5
\end{amatrix}
\grstep{ L_3 - 2 L_1 }
\begin{amatrix}{4}
1 &  1 & 0 &   0 & 4 \\
0 &  5 & 0 & -15 & 2 \\
0 &  0 & 1 &   0 & 4 \\
0 & -1 & 0 &   8 & 3/5
\end{amatrix} \\
\grstep{ \frac{1}{5} L_2 }
\begin{amatrix}{4}
1 &  1 & 0 &   0 & 4 \\
0 &  1 & 0 & -3 & 2/5 \\
0 &  0 & 1 &   0 & 4 \\
0 & -1 & 0 &   8 & 3/5
\end{amatrix}
&
\grstep{ L_4 + L_2 }
\begin{amatrix}{4}
1 & 1 & 0 &  0 & 4 \\
0 & 1 & 0 & -3 & 2/5 \\
0 & 0 & 1 &  0 & 4 \\
0 & 0 & 0 &  5 & 1
\end{amatrix}
\grstep{ \frac{1}{5} L_4 }
\begin{amatrix}{4}
1 & 1 & 0 &  0 & 4 \\
0 & 1 & 0 & -3 & 2/5 \\
0 & 0 & 1 &  0 & 4 \\
0 & 0 & 0 &  1 & 1/5
\end{amatrix} \\
\grstep{ L_2 + 3L_4 }
\begin{amatrix}{4}
1 & 1 & 0 & 0 & 4 \\
0 & 1 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 & 4 \\
0 & 0 & 0 & 1 & 1/5
\end{amatrix}
&
\grstep{ L_1 - L_2 }
\begin{amatrix}{4}
1 & 0 & 0 & 0 & 3 \\
0 & 1 & 0 & 0 & 1 \\
0 & 0 & 1 & 0 & 4 \\
0 & 0 & 0 & 1 & 1/5
\end{amatrix}
\end{align*}
Esta última matriz está associada às equações
\[
\left\{
\begin{aligned}
x_1 & = 3 \\
x_2 & = 1 \\
x_3 & = 4 \\
x_4 & = 1/5 \\
\end{aligned}
\right.,
\]
de modo que $S = \{ ( 3, 1, 4, 1/5 ) \}$ é o conjunto das soluções do sistema proposto.
\item A redução à forma escalonada reduzida da matriz associada ao sistema é obtida através das seguintes operações elementares:\begin{align*}
\begin{amatrix}{5}
  3 & -12 & -6 & 0 &    9 & -21 \\
 -1 &   4 &  2 & 0 &   -3 &  7 \\
1/2 &  -2 & -1 & 1 & -3/2 & -5/2 \\
 -7 &  28 & 15 & 0 & -23  & 53
\end{amatrix}
&
\grstep{ \frac{1}{3} L_1 }
\begin{amatrix}{5}
  1 & -4 & -2 &  0 &   3 & -7 \\
 -1 &  4 &  2 & 0 &  -3 &   7 \\
1/2 & -2 & -1 & 1 & -3/2 & -5/2 \\
 -7 & 28 & 15 & 0 & -23 & 53
\end{amatrix} \\
\grstep[ L_3 - \frac{1}{2} L_1 \\ L_4 + 7 L_1 ]{ L_2 + L_1 }
\begin{amatrix}{5}
1 & -4 & -2 &   0 &  3 & -7 \\
0 &  0 &  0 &   0 &  0 &  0 \\
0 &  0 &  0 &   1 & -3 & 1 \\
0 &  0 &  1 &   0 & -2 & 4
\end{amatrix}
&
\grstep{ L_2 \leftrightarrow L_4 }
\begin{amatrix}{5}
1 & -4 & -2 &   0 &  3 & -7 \\
0 &  0 &  1 &   0 & -2 & 4 \\
0 &  0 &  0 &   1 & -3 & 1 \\
0 &  0 &  0 &   0 &  0 &  0
\end{amatrix} \\
\grstep{ L_1 +2 L_2 }
\begin{amatrix}{5}
1 & -4 & 0 & 0 & -1 & 1 \\
0 &  0 & 1 & 0 & -2 & 4 \\
0 &  0 & 0 & 1 & -3 & 1 \\
0 &  0 & 0 & 0 &  0 &  0
\end{amatrix}
\end{align*}
Esta última matriz está associada às equações
\[
\left\{
\begin{aligned}
x_1 -4x_2-x_5 & =1 \\
x_3 -2x_5 & =4 \\
x_4 -3x_5 & =1 \\
0 & = 0.
\end{aligned}
\right.
\]

Logo, o conjunto das soluções do sistema proposto é
\begin{align*}
S
& = \{ (x_1, x_2, x_3, x_4, x_5 ) \in \R^5 \mid x_1 = 1 + 4x_2 + x_5, x_2 = 4 + 2x_5, x_4 = 1 + 3 x_5 \} \\
& = \{ (1 + 4x_2 + x_5, 4 + 2x_5, x_3, 1 + 3 x_5, x_5 ) \mid x_3,x_5 \in \R \}.
\end{align*}

\item

A matriz aumentada associada ao sistema dado é $[A|B] = 
\begin{amatrix}{3}
 0 &  1 &  6 &  6 \\
 1 &  6 & -5 & -3 \\
 3 & 20 & -3 &  1
\end{amatrix}$
e sua forma escalonada reduzida é obtida por meio das seguintes operações elementares sobre as linhas:


\begin{align*}
[A|B]
\grstep{ L_1 \leftrightarrow L_2 }
\begin{amatrix}{3}
 1 &  6 & -5 & -3 \\
 0 &  1 &  6 &  6 \\
 3 & 20 & -3 &  1
\end{amatrix}
&
\grstep{ L_3 - 3 L_1 }
\begin{amatrix}{3}
 1 & 6 & -5 & -3 \\
 0 & 1 &  6 &  6 \\
 0 & 2 & 12 & 10
\end{amatrix}
\grstep{ L_3 - 2 L_1 }
\begin{amatrix}{3}
 1 & 6 & -5 & -3 \\
 0 & 1 &  6 &  6 \\
 0 & 0 &  0 & -2
\end{amatrix} \\
\grstep{ \frac{-1}{2} L_3 }
\begin{amatrix}{3}
 1 & 6 & -5 & -3 \\
 0 & 1 &  6 &  6 \\
 0 & 0 &  0 & 1
\end{amatrix}
&
\grstep[ L_1 + 3 L_3 ]{ L_2 - 6 L_3 }
\begin{amatrix}{3}
 1 & 6 & -5 & 0 \\
 0 & 1 &  6 & 0 \\
 0 & 0 &  0 & 1
\end{amatrix}
\grstep{ L_1 - 6 L_2 }
\begin{amatrix}{3}
 1 & 0 & -41 & 0 \\
 0 & 1 &  6 & 0 \\
 0 & 0 &  0 & 1
\end{amatrix}
\end{align*}
Como a última linha corresponde a uma equação da forma $0 = 1$, o sistema é impossível, ou seja, $S = \emptyset$.

\end{enumerate}

\item
\begin{enumerate}
\item Primeiro é preciso determinar a inversa de $A$, e para isso serão usadas as mesmas operações elementares que produziram a forma escalonada reduzida de $A$:
\begin{align*}
\begin{bmatrix}
 5 & -5\pi & 1 & 0\\
-1 & \pi+3 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{5} L_1 }
\begin{bmatrix}
 1 & -\pi & 1/5 & 0 \\
-1 & \pi+3 & 0 & 1
\end{bmatrix}
\grstep{ L_2 + L_1 }
\begin{bmatrix}
1 & -\pi & 1/5 & 0 \\
0 &    3 & 1/5 & 1
\end{bmatrix} \\
&
\grstep{ \frac{1}{3} L_2 }
\begin{bmatrix}
1 & -\pi & 1/5 & 0 \\
0 &    1 & 1/15 & 1/3
\end{bmatrix}
\grstep{ L_1 + \pi L_2 }
\begin{bmatrix}
1 & 0 & 1/5 + \pi/15 & \pi/3 \\
0 & 1 &         1/15 & 1/3
\end{bmatrix}
\end{align*}
Assim, $A^{-1} =
\begin{bmatrix}
1/5 + \pi/15 & \pi/3 \\
        1/15 & 1/3
\end{bmatrix}
=
\frac{1}{15}
\begin{bmatrix}
3 + \pi & 5\pi \\
1       & 5
\end{bmatrix}.$

Sempre que $A X = B$ e $A$ é inversível, vale $X = A^{-1} B$. Assim, para $B = \begin{bmatrix}
-5\pi^2 \\
\pi(\pi+6)
\end{bmatrix}$, tem-se
\[
X
%= A^{-1} B
=
\frac{1}{15}
\begin{bmatrix}
3 + \pi & 5\pi \\
1       & 5
\end{bmatrix}
\cdot 
\begin{bmatrix}
-5\pi^2 \\
\pi(\pi+6)
\end{bmatrix}
=
\frac{1}{15}
\begin{bmatrix}
-5\pi^2(3 + \pi) + 5\pi^2(\pi+6) \\
-5\pi^2 + 5\pi(\pi+6)
\end{bmatrix}
=
\begin{bmatrix}
\pi^2 \\
2 \pi
\end{bmatrix}.
\]

\item Primeiro, determina-se $A^{-1}$ usando as mesmas operações elementares que produziram a forma escalonada reduzida de $A$:
\begin{align*}
\begin{bmatrix}
4 &  4 & 0 &   0 & 1 & 0 & 0 & 0 \\
0 &  5 & 0 & -15 & 0 & 1 & 0 & 0 \\
2 &  2 & 1 &   0 & 0 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{4} L_1 }
\begin{bmatrix}
1 &  1 & 0 &   0 & 1/4 & 0 & 0 & 0 \\
0 &  5 & 0 & -15 & 0 & 1 & 0 & 0 \\
2 &  2 & 1 &   0 & 0 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix} \\
\grstep{ L_3 - 2 L_1 }
\begin{bmatrix}
1 &  1 & 0 &   0 & 1/4 & 0 & 0 & 0 \\
0 &  5 & 0 & -15 & 0 & 1 & 0 & 0 \\
0 &  0 & 1 &   0 & -1/2 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix}
& 
\grstep{ \frac{1}{5} L_2 }
\begin{bmatrix}
1 &  1 & 0 &   0 & 1/4 & 0 & 0 & 0 \\
0 &  1 & 0 & -3 & 0 & 1/5 & 0 & 0 \\
0 &  0 & 1 &   0 & -1/2 & 0 & 1 & 0 \\
0 & -1 & 0 &   8 & 0 & 0 & 0 & 1
\end{bmatrix} \\
\grstep{ L_4 + L_2 }
\begin{bmatrix}
1 & 1 & 0 &  0 & 1/4 & 0 & 0 & 0 \\
0 & 1 & 0 & -3 & 0 & 1/5 & 0 & 0 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  5 & 0 & 1/5 & 0 & 1
\end{bmatrix}
&
\grstep{ \frac{1}{5} L_4 }
\begin{bmatrix}
1 & 1 & 0 &  0 & 1/4 & 0 & 0 & 0 \\
0 & 1 & 0 & -3 & 0 & 1/5 & 0 & 0 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  1 & 0 & 1/25 & 0 & 1/5
\end{bmatrix} \\
\grstep{ L_2 + 3L_4 }
\begin{bmatrix}
1 & 1 & 0 &  0 & 1/4 & 0 & 0 & 0 \\
0 & 1 & 0 &  0 & 0 & 8/25 & 0 & 3/5 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  1 & 0 & 1/25 & 0 & 1/5
\end{bmatrix}
&
\grstep{ L_1 - L_2 }
\begin{bmatrix}
1 & 0 & 0 &  0 & 1/4 & -8/25 & 0 & -3/5 \\
0 & 1 & 0 &  0 & 0 & 8/25 & 0 & 3/5 \\
0 & 0 & 1 &  0 & -1/2 & 0 & 1 & 0 \\
0 & 0 & 0 &  1 & 0 & 1/25 & 0 & 1/5
\end{bmatrix}
\end{align*}

Assim, $A^{-1} =
\begin{bmatrix}
 1/4 & -8/25 & 0 & -3/5 \\
   0 &  8/25 & 0 & 3/5  \\
-1/2 &     0 & 1 & 0    \\
   0 &  1/25 & 0 & 1/5
\end{bmatrix}
=
\frac{1}{100}
\begin{bmatrix}
 25 & -32 &   0 & -60 \\
  0 &  32 &   0 &  60 \\
-50 &   0 & 100 &   0 \\
  0 &   4 &   0 &  20
\end{bmatrix}$ e a solução $X = 
\begin{bmatrix}
x_1 \\
x_2 \\
x_3 \\
x_4
\end{bmatrix}$ do sistema é obtida através da seguinte multiplicação:

\[
X
= A^{-1} B
=
\frac{1}{100}
\begin{bmatrix}
 25 & -32 &   0 & -60 \\
  0 &  32 &   0 &  60 \\
-50 &   0 & 100 &   0 \\
  0 &   4 &   0 &  20
\end{bmatrix}
\cdot
\begin{bmatrix}
16 \\
 2 \\
12 \\
3/5
\end{bmatrix}
=
\frac{1}{100}
\begin{bmatrix}
300 \\
100 \\
400 \\
20
\end{bmatrix}
=
\begin{bmatrix}
3 \\
1 \\
4 \\
1/5
\end{bmatrix}
\]

\item A matriz (não aumentada) associada ao sistema não é quadrada.
\item A matriz associada ao sistema não é inversível, pois sua forma escalonada reduzida não é a matriz identidade.
\end{enumerate}

\newpage
\item Os três sistemas podem ser escritos na forma $AX=B$ com uma mesma matriz $A = \begin{bmatrix}
0 & -1 & 5 \\
1 & 2 & 3 \\
2 & 4 & 5
\end{bmatrix}$, então será preciso calcular apenas uma matriz inversa:
\begin{align*}
\begin{bmatrix}
0 & -1 & 5 & 1 & 0 & 0\\
1 & 2 & 3 & 0 & 1 & 0\\
2 & 4 & 5 & 0 & 0 & 1
\end{bmatrix}
&
\grstep{ L_1 \swap L2 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & -1 & 5 & 1 & 0 & 0\\
2 & 4 & 5 & 0 & 0 & 1
\end{bmatrix}
\grstep{ L_3 - 2 L1 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & -1 & 5 & 1 & 0 & 0\\
0 & 0 & -1 & 0 & -2 & 1
\end{bmatrix} \\
&
\grstep{ -L_2 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & 1 & -5 & -1 & 0 & 0\\
0 & 0 & -1 & 0 & -2 & 1
\end{bmatrix}
\grstep{ -L_3 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & 1 & -5 & -1 & 0 & 0\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix} \\
&
\grstep{ L2+5L_3 }
\begin{bmatrix}
1 & 2 & 3 & 0 & 1 & 0\\
0 & 1 & 0 & -1 & 10 & -5\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix}
\grstep{ L_1-3L_3 }
\begin{bmatrix}
1 & 2 & 0 & 0 & -5 & 3\\
0 & 1 & 0 & -1 & 10 & -5\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix} \\
&
\grstep{ L_1-2L_2 }
\begin{bmatrix}
1 & 0 & 0 & 2 & -25 & 13\\
0 & 1 & 0 & -1 & 10 & -5\\
0 & 0 & 1 & 0 & 2 & -1
\end{bmatrix}.
\end{align*}
Disto resulta que $A^{-1} = \begin{bmatrix}
 2 & -25 & 13\\
-1 &  10 & -5\\
 0 & 2 & -1
\end{bmatrix}$.

\begin{enumerate}
\item Se $X = \begin{bmatrix}
x\\
y\\
z
\end{bmatrix}$ e $B = \begin{bmatrix}
2\\
7\\
13
\end{bmatrix}$ então:
$
X
= A^{-1} B
=
\begin{bmatrix}
 2 & -25 & 13\\
-1 &  10 & -5\\
 0 & 2 & -1
\end{bmatrix}
\begin{bmatrix}
2\\
7\\
13
\end{bmatrix}
=
\begin{bmatrix}
-2\\
3\\
1
\end{bmatrix}.
$

\item Se $X = \begin{bmatrix}
u\\
v\\
w
\end{bmatrix}$ e $B = \begin{bmatrix}
0\\
0\\
0
\end{bmatrix}$ então $X = \begin{bmatrix}
0\\
0\\
0
\end{bmatrix}$ pois $A$ é inversível.

\item Se $X = \begin{bmatrix}
p\\
q\\
r
\end{bmatrix}$ e $B = \begin{bmatrix}
-2\\
3\\
1
\end{bmatrix}$ então:
$
X
= A^{-1} B
=
\begin{bmatrix}
 2 & -25 & 13\\
-1 &  10 & -5\\
 0 & 2 & -1
\end{bmatrix}
\begin{bmatrix}
-2\\
3\\
1
\end{bmatrix}
=
\begin{bmatrix}
-66\\
27\\
5
\end{bmatrix}.
$
\end{enumerate}

\item A matriz $(B + C^T) ((AB)^T + CA^T)$ tem tamanho $q \times p$, pois
\begin{itemize}
\item $B$ e $C^T$ têm tamanho $q \times r$, de modo que $B + C^T$ também é $q \times r$.
\item $AB$ têm tamanho $p \times r$, de modo que $(AB)^T$ é $r \times p$.
\item $A^T$ têm tamanho $q \times p$, de modo que $CA^T$ é $r \times p$.
\item O produto de qualquer matriz $q \times r$ por uma matriz $r \times p$ tem tamanho $q \times p$.
\end{itemize}

\item
\begin{enumerate}
\item Para quaisquer $m$ e $n$, se $X$ é $m \times n$ então sua transposta $X^T$ é $n \times m$. Em particular, o número de colunas de $X$ é sempre igual ao número de linhas de $X^T$, e estas matrizes podem ser multiplicadas (nesta ordem), gerando um produto que é $m \times m$. Além disso, $X X^T$ é simétrica pois
\[
(X X^T)^T = (X^T)^T X^T = X X^T.
\]
\item De forma análoga ao item anterior, o número de colunas de $X^T$ é sempre igual ao número de linhas de $X$, e estas matrizes podem ser multiplicadas (nesta ordem), desta vez gerando um produto que é $n \times n$. Além disso, $X^T X$ também é simétrica:
\[
(X^T X)^T = X^T (X^T)^T = X^T X.
\]
\item Para que seja possível calcular $X + X^T$, é necessário que $X$ e $X^T$ tenham o mesmo tamanho. Como uma delas é $m \times n$ e a outra é $n \times m$, a adição só será possível se $m = n$. Neste caso, a soma será uma matriz simétrica, pois
\[
(X + X^T)^T = X^T + (X^T)^T = X^T + X = X + X^T.
\]
\item Como no item anterior, para que $X^T + X$ faça sentido é preciso que $X$ e $X^T$ tenham o mesmo tamanho, isto é, que $m = n$. Neste caso, a soma também será uma matriz simétrica, já que
\[
(X^T + X)^T = (X^T)^T + X^T = X + X^T = X^T + X.
\]
\item Novamente, é preciso que $m=n$ para que a operação $X - X^T$ seja possível. No entanto, neste caso
\[
(X - X^T)^T = X^T - (X^T)^T = X^T - X = -(X - X^T).
\]
No entanto, $D = X - X^T$ só será igual a $-(X - X^T)$ se $d_{ij} = -d_{ij}$, para cada $i,j$, e isso só é possível se todos os $d_{ij}$ forem nulos. Em outras palavras, $X - X^T$ só é uma matriz simétrica se $X - X^T = 0$.
\end{enumerate}

\item Há duas possibilidades, dependendo das entradas da primeira coluna:
\begin{enumerate}
\item Se $a \neq 0$ então a redução à forma escalonada reduzida começa com as seguintes operações elementares:
\begin{align*}
\begin{amatrix}{2}
a & b & 0 \\
c & d & 0
\end{amatrix}
&
\grstep{ \frac{1}{a} L_1 }
\begin{amatrix}{2}
1 & \frac{b}{a} & 0 \\
c & d & 0
\end{amatrix}
\grstep{ L_2 - c L_1 }
\begin{amatrix}{2}
1 & \frac{b}{a} & 0 \\
0 & d-c\frac{b}{a} & 0
\end{amatrix}
=
\begin{amatrix}{2}
1 & \frac{b}{a} & 0 \\
0 & \frac{ad-bc}{a} & 0
\end{amatrix}
\end{align*}
Neste ponto, a hipótese de que $ad-bc \neq 0$ pode ser usada para concluir a eliminação:
\begin{align*}
\begin{amatrix}{2}
1 & \frac{b}{a} & 0 \\
0 & \frac{ad-bc}{a} & 0
\end{amatrix}
&
\grstep{ \frac{a}{ad-bc} L_2 }
\begin{amatrix}{2}
1 & \frac{b}{a} & 0 \\
0 & 1 & 0
\end{amatrix}
\grstep{ L_1 - \frac{b}{a} L_2 }
\begin{amatrix}{2}
1 & 0 & 0 \\
0 & 1 & 0
\end{amatrix}.
\end{align*}
Assim, o sistema $MX = 0$ só tem a solução trivial $X = 0$.

\item Se $a = 0$ então uma troca da primeira linha com a segunda faz com que o problema recaia no caso anterior, em que a primeira entrada da primeira linha não é zero. Note que neste caso $c$ não será zero, pois senão ocorreria $ad-bc = 0 \cdot d-b \cdot 0 = 0$.
\end{enumerate}
\textbf{Observação:} Note que $ad-bc$ é justamente a fórmula do determinante da matriz $\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}$.

\item Como
\[
MX = \begin{bmatrix}
-1 &  2 & 3 \\
 2 & -4 & 5 \\
-1 &  1 & 7
\end{bmatrix}
\begin{bmatrix}
a & b & c \\
d & e & f \\
g & h & i
\end{bmatrix}
=
\begin{bmatrix}
-a + 2d + 3g & -b + 2e + 3h & -c + 2f + 3i \\
2a - 4d + 5g & 2b - 4e + 5h & 2c - 4f + 5i \\
-a +  d + 7g & -b +  e + 7h & -c +  f + 7i
\end{bmatrix}
\]
e por hipótese $MX = I$, uma comparação das entradas de $MX$ com as de $I$ mostra que as incógnitas que formam as colunas de $X$ devem ser soluções dos sistemas lineares
\[
\systeme[adg]{
-a + 2d + 3g = 1,
2a - 4d + 5g = 0,
-a +  d + 7g = 0
}, 
\systeme[adg]{
-a + 2d + 3g = 0,
2a - 4d + 5g = 1,
-a +  d + 7g = 0
} \text{ e }
\systeme[adg]{
-a + 2d + 3g = 0,
2a - 4d + 5g = 1,
-a +  d + 7g = 0
}.
\]

Como todos os sistemas têm a mesma matriz de coeficientes, os três podem ser escalonados simultaneamente como segue:

\begin{align*}
&
\begin{bmatrix}
-1 &  2 & 3 & 1 & 0 & 0\\
 2 & -4 & 5 & 0 & 1 & 0\\
-1 &  1 & 7 & 0 & 0 & 1
\end{bmatrix}
\grstep{ -L_1 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 2 & -4 &  5 &  0 & 1 & 0\\
-1 &  1 &  7 &  0 & 0 & 1
\end{bmatrix} \\
\grstep{ L_2 - 2 L_1 }
& \begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 0 &  0 & 11 &  2 & 1 & 0\\
-1 &  1 &  7 &  0 & 0 & 1
\end{bmatrix}
\grstep{ L_3 + L_1 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 0 &  0 & 11 &  2 & 1 & 0\\
 0 & -1 &  4 & -1 & 0 & 1
\end{bmatrix} \\
\grstep{ L_2 \swap L_3 }
& \begin{bmatrix}
 1 & -2 & -3 & -1 & 0 & 0\\
 0 & -1 &  4 & -1 & 0 & 1\\
 0 &  0 & 11 &  2 & 1 & 0
\end{bmatrix}
\grstep{ -L_2 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 &  0\\
 0 &  1 & -4 &  1 & 0 & -1\\
 0 &  0 & 11 &  2 & 1 &  0
\end{bmatrix} \\
\grstep{ \frac{1}{11} L_3 }
&
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 &  0\\
 0 &  1 & -4 &  1 & 0 & -1\\
 0 &  0 &  1 & 2/11 & 1/11 &  0
\end{bmatrix}
\grstep{ L_2 +4 L_3 }
\begin{bmatrix}
 1 & -2 & -3 & -1 & 0 &  0\\
 0 &  1 &  0 & 19/11 & 4/11 & -1\\
 0 &  0 &  1 & 2/11 & 1/11 &  0
\end{bmatrix} \\
\grstep{ L_1 + 3 L_3 }
&
\begin{bmatrix}
 1 & -2 & 0 & -5/11 & 3/11 &  0\\
 0 &  1 & 0 & 19/11 & 4/11 & -1\\
 0 &  0 & 1 &  2/11 & 1/11 &  0
\end{bmatrix}
\grstep{ L_1 + 2 L_2 }
\begin{bmatrix}
 1 & 0 & 0 & 3 & 1 & -2\\
 0 & 1 & 0 & 19/11 & 4/11 & -1\\
 0 & 0 & 1 &  2/11 & 1/11 &  0
\end{bmatrix}
\end{align*}
Assim,
$X = \begin{bmatrix}
    3 &    1 & -2\\
19/11 & 4/11 & -1\\
 2/11 & 1/11 &  0
\end{bmatrix}$. Multiplicando esta matriz à esquerda de $M$, obtém-se:
\[
XM =
\begin{bmatrix}
    3 &    1 & -2\\
19/11 & 4/11 & -1\\
 2/11 & 1/11 &  0
\end{bmatrix}
\begin{bmatrix}
-1 &  2 & 3 \\
 2 & -4 & 5 \\
-1 &  1 & 7
\end{bmatrix}
=\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}.
\]
Isto quer dizer que a matrix $X$ que atua como inversa à direita de $A$ também é uma inversa à esquerda de $A$, pois ambos os produtos ($AX$ e $XA$) resultam na matriz identidade.


\item 
\begin{enumerate}
\item Ao sortear 10 matrizes $7 \times 7$ \textit{aleatoriamente}, é bem provavel que \textbf{todas} as matrizes obtidas sejam inversíveis (execute o comando mais de 10 vezes se não estiver convencido).
\item Repetindo o experimento com matrizes quadradas de qualquer outro tamanho, há grandes chances de não encontrar uma única matriz que não seja inversível. De fato, ao sortear \textit{aleatoriamente} uma matriz quadrada, há \textbf{probabilidade zero} (não é só pequena, é zero!) de ser escolhida uma matriz não inversível. Elas são raras, mas pode se deparar com elas se estiver com sorte (ou se o sorteio não for realmente aleatório).

\item Sejam $A_2 =
\begin{bmatrix}
0 & 5 \\
0 & 0
\end{bmatrix}$, $A_3 =
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}$ e $A_4 =
\begin{bmatrix}
0 & -1 & 2 & 3 \\
0 &  0 & 1 & 5 \\
0 &  0 & 0 & 7 \\
0 &  0 & 0 & 0
\end{bmatrix}$. Então:
\begin{enumerate}
\item
\begin{align*}
A_2^2 & =
\begin{bmatrix}
0 & 5 \\
0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & 5 \\
0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 \\
0 & 0
\end{bmatrix}, \\
A_3^3 & =
\left(
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}
\right)
\cdot
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix} \\
& =
\begin{bmatrix}
0 & 0 & -10 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & -2 & 1 \\
0 &  0 & 5 \\
0 &  0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix},\\
A_4^4 & =
\begin{bmatrix}
0 & -1 & 2 & 3 \\
0 &  0 & 1 & 5 \\
0 &  0 & 0 & 7 \\
0 &  0 & 0 & 0
\end{bmatrix}^2
\cdot
\begin{bmatrix}
0 & -1 & 2 & 3 \\
0 &  0 & 1 & 5 \\
0 &  0 & 0 & 7 \\
0 &  0 & 0 & 0
\end{bmatrix}^2
=
\begin{bmatrix}
0 & 0 & -1 & 9 \\
0 & 0 & 0 & 7 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}^2
=
\begin{bmatrix}
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0
\end{bmatrix}.
\end{align*}

\item Com base nos exemplos anteriores, é natural suspeitar que a $n$-ésima potência de uma matriz triangular superior $n\times n$ qualquer, com zeros na diagonal, é sempre a matriz nula $n\times n$.
\item As matrizes triangulares superiores de tamanho $2 \times 2$, com zeros na diagonal, têm a forma $A_2 =
\begin{bmatrix}
0 & c\\
0 & 0
\end{bmatrix}$, em que $c$ pode ser qualquer escalar. Então:
\[
A_2^2 =
\begin{bmatrix}
0 & c\\
0 & 0
\end{bmatrix}
\begin{bmatrix}
0 & c\\
0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0\\
0 & 0
\end{bmatrix}
\]
Já no caso $3 \times 3$, tem-se $A_3=
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}$ e então:
\[
A_3^3 =
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}^2
\cdot
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & ac \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}
\cdot
\begin{bmatrix}
0 & a & b \\
0 & 0 & c \\
0 & 0 & 0
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & 0 \\
0 & 0 & 0 \\
0 & 0 & 0
\end{bmatrix}.
\]
Mais geralmente, se $A = (a_{ij})$ for uma matriz triangular superior de tamanho $n \times n$ com diagonal nula, então as primeiras $i$ entradas da linha $i$ são todas nulas. Ao elevar $A$ ao quadrado, a matriz obtida terá as primeiras $i+1$ entradas da linha $i$ iguais a zero. Analogamente, ao calcular $A^3$, a matriz resultante terá $i+2$ entradas da linha $i$ igual a zero. Como a matriz tem $n$ colunas, procedendo desta maneira até obter $A^n$ o resultado final será uma matriz com zeros em todas as $n$ colunas de cada linha.
\[
\overset{A}{
\overbrace{
\begin{bmatrix}
\textbf{0} &     a_{12} & a_{13} & \ldots & a_{1n} \\
         0 & \textbf{0} & a_{23} & \ldots & a_{2n} \\
    \vdots &     \vdots & \ddots & \ddots & \vdots \\
         0 &          0 &      0 & \ddots & a_{n-1,n} \\
         0 &          0 &      0 & \ldots & \textbf{0}
\end{bmatrix}
}}
\rightarrow
\overset{A^2}{
\overbrace{
\begin{bmatrix}
         0 & \textbf{0} & a_{13} & \ldots & a_{1n} \\
         0 &          0 & \textbf{0} & \ldots & a_{2n} \\
    \vdots &     \vdots &     \ddots & \ddots & \vdots \\
         0 &          0 &          0 & \ddots & \textbf{0} \\
         0 &          0 &          0 & \ldots & 0
\end{bmatrix}
}}
%\rightarrow
\ldots \rightarrow
\overset{A^n}{
\overbrace{
\begin{bmatrix}
         0 &          0 &          0 & \ldots & \textbf{0} \\
         0 &          0 &          0 & \ldots & 0 \\
    \vdots &     \vdots &     \ddots & \ddots & \vdots \\
         0 &          0 &          0 & \ddots & 0 \\
         0 &          0 &          0 & \ldots & 0
\end{bmatrix}
}}
\]

O padrão acima também pode ser percebido ao calcular explicitamente as entradas dos produtos. Como a matriz $A$ é triangular superior e tem zeros na diagonal, tem-se $a_{ij} = 0$ sempre que $i \geq j$. Consequentemente, se $i \geq j-1$ a entrada $ij$ de $A^2$ é dada por
\begin{align*}
[A^2]_{ij}
  = [A \cdot A]_{ij}
& = (a_{i1} a_{1j}       + \ldots + a_{ii} a_{ij})
  + (a_{i,i+1} a_{i+1,j} + \ldots + a_{in} a_{nj}) \\
& = (0 a_{1j}       + \ldots + 0 a_{ij})
  + (a_{i,i+1} 0 + \ldots + a_{in} 0)
  = 0.
\end{align*}
Do mesmo modo, $[A^3]_{ij} = 0$ para $i \geq j-2$:
\begin{align*}
[A^3]_{ij}
  = [A^2 \cdot A]_{ij}
& = ([A^2]_{i1} a_{1j} + \ldots + [A^2]_{i,i+1} a_{i+1,j}) \\
& \quad + ([A^2]_{i,i+2} a_{i+2,j} + \ldots + [A^2]_{in} a_{nj}) \\
& = (0 a_{1j}       + \ldots + 0 a_{i+1,j})
  + ([A^2]_{i+2,j+1} 0 + \ldots + [A^2]_{in} 0)
  = 0.
\end{align*}
Procedendo da mesma maneira até a $n$-ésima potência de $A$, consegue-se todas as entradas iguais a zero.
\end{enumerate}
\end{enumerate}


\item Para que a matriz $T =
\begin{bmatrix}
-1 & 9 & 1 \\
-1 & t & 3 \\
-1 & 9 & t + 1
\end{bmatrix}$
seja inversível, sua forma escalonada reduzida por linhas deve ser a matriz identidade. Procedendo com a eliminação de Gauss-Jordan, seriam realizadas as seguintes operações elementares sobre as linhas:
\begin{align*}
\begin{bmatrix}
-1 & 9 & 1 \\
-1 & t & 3 \\
-1 & 9 & t + 1
\end{bmatrix}
\grstep{ -L_1 }
\begin{bmatrix}
1 & -9 & -1 \\
-1 & t & 3 \\
-1 & 9 & t + 1
\end{bmatrix}
\grstep{ L_2 + L_1 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & t-9 & 2 \\
-1 & 9 & t + 1
\end{bmatrix}
\grstep{ L_3 + L_1 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & t-9 & 2 \\
0 & 0 & t
\end{bmatrix}
\end{align*}
Neste ponto, para conseguir um pivô igual a $1$ na segunda coluna da segunda linha, seria necessária uma divisão da segunda linha por $t - 9$, e isso significa que se $t=9$ a matriz não será inversível. Além disso, no passo seguinte, será necessário dividir a terceira linha por $t$, de modo que para $t = 0$ a matriz também não será inversível. Supondo que $t \neq 0$ e $t \neq 9$, basta realizar mais algumas operações elementares e obtém-se a identidade:
\begin{align*}
\begin{bmatrix}
1 & -9 & -1 \\
0 & t-9 & 2 \\
0 & 0 & t
\end{bmatrix}
\grstep{ \frac{1}{t-9} L_2 }
&\begin{bmatrix}
1 & -9 & -1 \\
0 & 1 & \frac{2}{t-9} \\
0 & 0 & t
\end{bmatrix}
\grstep{ \frac{1}{t} L_3 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & 1 & \frac{2}{t-9} \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_2 -\frac{2}{t-9} L_3 }
\begin{bmatrix}
1 & -9 & -1 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}\\
\grstep{ L_1 + L_3 }
&\begin{bmatrix}
1 & -9 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_1 + 9L_2 }
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}.
\end{align*}
Portanto, $T$ é inversível se, e somente se, $t \not \in \{0, 9\}$.
Aplicando a mesma sequência de operações elementares à matriz identidade, o resultado é a inversa de $T$:
0\begin{align*}
I
& \grstep{ -L_1 }
\begin{bmatrix}
-1 & 0 & 0 \\
 0 & 1 & 0 \\
 0 & 0 & 1
\end{bmatrix}
\grstep[ L_3 + L_1 ]{ L_2 + L_1 }
\begin{bmatrix}
-1 & 0 & 0 \\
-1 & 1 & 0 \\
-1 & 0 & 1
\end{bmatrix}
\grstep[\frac{1}{t} L_3]{ \frac{1}{t-9} L_2 }
\begin{bmatrix}
-1 & 0 & 0 \\
\frac{-1}{t-9} & \frac{1}{t-9} & 0 \\
\frac{-1}{t} & 0 & \frac{1}{t}
\end{bmatrix} \\
& \grstep{ L_2 -\frac{2}{t-9} L_3 }
\begin{bmatrix}
-1 & 0 & 0 \\
\frac{2-t}{(t-9)t} & \frac{1}{t-9} & \frac{-2}{(t-9)t} \\
\frac{-1}{t} & 0 & \frac{1}{t}
\end{bmatrix}
\grstep{ L_1 + L_3 }
\begin{bmatrix}
\frac{-t-1}{t} & 0 & \frac{1}{t} \\
\frac{2-t}{(t-9)t} & \frac{1}{t-9} & \frac{-2}{(t-9)t} \\
\frac{-1}{t} & 0 & \frac{1}{t}
\end{bmatrix}\\
&\grstep{ L_1 + 9L_2 }
\begin{bmatrix}
\dfrac{-t^2 - t + 27}{(t-9)t} & \dfrac{9}{t-9} & \dfrac{t-27}{(t-9)t}\\
\dfrac{2-t}{(t-9)t} & \dfrac{1}{t-9} & \dfrac{-2}{(t-9)t}\\
\dfrac{-1}{t} & 0 & \dfrac{1}{t}
\end{bmatrix} = T^{-1}.
\end{align*}


\item As operações elementares a seguir mostram que $N$ é equivalente por linhas à identidade, desde que seja possível dividir por $1-t$ e depois por $t(t+2)$. Isto significa que para $t \in\{ -2, 0, 1 \}$ a matriz $N$ não é inversível, pois apareceria uma linha nula em um dos passos da eliminação de Gauss-Jordan.
\begin{align*}
N= & \begin{bmatrix}
2-t & 0 & -4 \\
6 & 1-t & -15 \\
2 & 0 & -4-t
\end{bmatrix}
\grstep{ L_1 \swap L_3 }
\begin{bmatrix}
2 & 0 & -4-t \\
6 & 1-t & -15 \\
2-t & 0 & -4
\end{bmatrix}
\grstep{ \frac{1}{2} L_1 }
\begin{bmatrix}
1 & 0 & -2-\frac{t}{2} \\
6 & 1-t & -15 \\
2-t & 0 & -4
\end{bmatrix} \\
\grstep{ L_2 - 6 L_1 }
& \begin{bmatrix}
1 & 0 & -2-\frac{t}{2} \\
0 & 1-t & 3(t-1) \\
2-t & 0 & -4
\end{bmatrix}
\grstep{ L_3 - (2-t) L_1 }
\begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1-t & 3(t-1) \\
0 & 0 & -\frac{t(t+2)}{2}
\end{bmatrix}
\grstep{ \frac{1}{1-t} L_2 }
\begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1 & -3 \\
0 & 0 & -\frac{t(t+2)}{2}
\end{bmatrix}\\
\grstep{ -\frac{2}{t(t+2)} L_2 }
& \begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1 & -3 \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_2 + 3 L_3}
\begin{bmatrix}
1 & 0 & \frac{-4-t}{2} \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}
\grstep{ L_1 -\frac{4+t}{2} L_3}
\begin{bmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{bmatrix}.
\end{align*}

\item
\begin{enumerate}
\item A matriz nula é uma matriz na forma escalonada reduzida por linhas, pois 
\begin{itemize}
\item Não há nenhuma linha não nula em que o primeiro elemento não nulo seja diferente de 1 (nem sequer existem linhas não nulas);
\item Todas as linhas nulas estão na parte inferior
\item Não há pivôs mais a esquerda dos pivôs de linhas anteriores (já que não há pivôs)
\item Não há elementos não nulos acima ou abaixo de nenhum pivô
\end{itemize}
\item A matriz identidade $I_{4 \times 4}$ está na forma escalonada reduzida por linhas pois
\begin{itemize}
\item Em todas as linhas o o primeiro elemento não nulo é 1;
\item Não há linhas nulas
\item Todos os pivôs estão na diagonal
\item Exceto pelos pivôs que estão na diagonal, as colunas só contém zeros
\end{itemize}

\item Em uma matriz triangular superior $S \in M_{n \times n}(K)$, todos os elementos abaixo da diagonal principal são nulos, ou seja, $s_{ij} = 0$ sempre que $i > j$. Se $S$ é simétrica, então $s_{ij} = s_{ji}$, sendo $1 \leq i,j \leq n$. Em particular, se $i < j$ então $s_{ij} = s_{ji} = 0$, pois $j > i$. Logo, $T$ é uma matriz diagonal, já que $s_{ij} = 0$ sempre que que $i > j$ ou $i < j$, isto é, para $i \neq j$.

\item Se $U, V \in M_{m \times m} (K)$ são matrizes diagonais, então $UV = VU$. De fato, se $i \neq j$ então $u_{ij} = v_{ij} = 0$ e além disso
\[
\left[UV\right]_{ij}
= \sum_{k=1}^m u_{ik} v_{kj}
= u_{i1} v_{1j} + u_{i2} v_{2j} + \ldots + u_{im} v_{mj}.
\]
Nesta soma, tem-se $u_{ik} = 0$, exceto possivelmente quando $k = i$. Mesmo assim, a parcela $u_{ii}v_{ij}$ será nula, pois $k = i \neq j \Rightarrow v_{kj} = v_{ij} = 0$. Assim, todos os termos da soma são nulos, e as entradas $\left[UV\right]_{ij}$ são nulas sempre que $i \neq j$. De forma análoga, tem-se $\left[VU\right]_{ij} = 0 $ para $i \neq j$, ou seja, $UV$ e $VU$ coincidem fora da diagonal principal. Por outro lado, na diagonal principal tem-se $i = j$ e então
\[
\left[UV\right]_{ij} = u_{ii} v_{ii} = v_{ii} u_{ii} = \left[VU\right]_{ij}.
\]

\item Seja $A$ antissimétrica. Então $A^T = -A$ e resulta que $
\left( A^T \right)^T = A = -A^T$, ou seja, $A^T$ também é antissimétrica.

\item Dada uma matriz antissimétrica $A \in M_{n \times n}(\R)$, tem-se $[A]_{ij} = [A^T]_{ji} = -[A]_{ji}$. Em particular, se $i = j$, vale $[A]_{ii} = -[A]_{ii}$, o que implica que  $2[A]_{ii} = 0$, isto é,  $[A]_{ii} = 0$. Assim, todas as entradas da diagonal de $A$ são nulas.

\item A matriz nula $0 \in M_{n \times n}(\R)$ é simétrica e antissimétrica simultaneamente.

\end{enumerate}


\item Seja $D \in M_{2\times 2} (\R)$ uma matriz diagonal. Então
$
D = \begin{bmatrix}
x_1 & 0\\
0 & x_2
\end{bmatrix},
$
com $x_1, x_2 \in \R$
e tem-se
\begin{align*}
D^2
& =
\begin{bmatrix}
x_1 & 0 \\
0 & x_2
\end{bmatrix}^2
=
\begin{bmatrix}
x_1^2 & 0 \\
0 & x_2^2
\end{bmatrix}
=
\begin{bmatrix}
1 & 0\\
0 & 1
\end{bmatrix}.
\end{align*}
Assim, os escalares $x_1$ e $x_2$ satisfazem $x_i^2 = 1$, ou seja, $x_i = 1$ ou $x_i = -1$. Logo, $D$ pode ser uma destas 4 matrizes:
\[
\begin{bmatrix}
1 & 0\\
0 & 1
\end{bmatrix},
\begin{bmatrix}
1 & 0\\
0 & -1
\end{bmatrix},
\begin{bmatrix}
-1 & 0\\
0 & 1
\end{bmatrix}
\text{ e }
\begin{bmatrix}
-1 & 0\\
0 & -1
\end{bmatrix}
\]
No caso de matrizes $3 \times 3$, cada uma das três entradas da diagonal pode ser igual a $1$ ou a $-1$, e consequentemente $I = I_3$ tem 8 raízes quadradas distintas.

\item Seja $D \in M_{3 \times 3} (\R)$ uma matriz diagonal. Então
$
D = \begin{bmatrix}
x_1 & 0 & 0\\
0 & x_2 & 0\\
0 & 0 & x_3
\end{bmatrix},
$
com $x_1, x_2, x_3 \in \R$
e tem-se
\begin{align*}
D^2 - 7D + 10I
& =
\begin{bmatrix}
x_1 & 0 & 0\\
0 & x_2 & 0\\
0 & 0 & x_3
\end{bmatrix}^2
-7
\begin{bmatrix}
x_1 & 0 & 0\\
0 & x_2 & 0\\
0 & 0 & x_3
\end{bmatrix}
+10
\begin{bmatrix}
1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix} \\
& =
\begin{bmatrix}
x_1^2 - 7x_1 + 10& 0 & 0\\
0 & x_2^2 - 7x_2 + 10 & 0\\
0 & 0 & x_3^2 - 7x_3 + 10
\end{bmatrix}
=
\begin{bmatrix}
0 & 0 & 0\\
0 & 0 & 0\\
0 & 0 & 0
\end{bmatrix}.
\end{align*}
Assim, se $D^2 - 7D + 10I = 0$ os escalares $x_1$, $x_2$ e $x_3$ são soluções de $x_i^2 - 7x_i + 10 = 0$, ou seja, de $(x_i-2)(x_i-5)=0$. Portanto, cada $x_i$ pode assumir os valores $2$ ou $5$, e há as seguintes possibilidades para $D$:
{\footnotesize
\[
\begin{bmatrix}
2 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 2
\end{bmatrix},
\begin{bmatrix}
2 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 5
\end{bmatrix},
\begin{bmatrix}
2 & 0 & 0\\
0 & 5 & 0\\
0 & 0 & 2
\end{bmatrix},
\begin{bmatrix}
2 & 0 & 0\\
0 & 5 & 0\\
0 & 0 & 5
\end{bmatrix},
\begin{bmatrix}
5 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 2
\end{bmatrix},
\begin{bmatrix}
5 & 0 & 0\\
0 & 2 & 0\\
0 & 0 & 5
\end{bmatrix},
\begin{bmatrix}
5 & 0 & 0\\
0 & 5 & 0\\
0 & 0 & 2
\end{bmatrix}
\text{ e }
\begin{bmatrix}
5 & 0 & 0\\
0 & 5 & 0\\
0 & 0 & 5
\end{bmatrix}.
\]
}

\item Seja $S$ uma matriz simétrica $n \times n$, isto é, $S^T = S$. As entradas de $S^2$ e de $(S^2)^T$, são dadas por
\begin{equation}\label{eq:S-quadrado}
[S^2]_{ij}
= \sum_{k=1}^n s_{ik} s_{kj}
= s_{i1} s_{1j} + s_{i2} s_{2j} + \ldots + s_{in} s_{nj}
\end{equation}
e
\[
[(S^2)^T]_{ij}
= [S^2]_{ji}
= \sum_{k=1}^n s_{jk} s_{ki}
= s_{j1} s_{1i} + s_{j2} s_{2i} + \ldots + s_{jn} s_{ni}
\]
respectivamente. Mas as entradas de $S$ satisfazem a igualdade $s_{ij} = s_{ji}$, então resulta desta última equação, permutando os índices de cada termo, que
\begin{align*}
[(S^2)^T]_{ij}
& = s_{j1} s_{1i} + s_{j2} s_{2i} + \ldots + s_{jn} s_{ni} \\
& = s_{1j} s_{i1} + s_{2j} s_{i2} + \ldots + s_{nj} s_{in}\\
& = s_{i1} s_{1j} + s_{i2} s_{2j} + \ldots + s_{in} s_{nj},
\end{align*}
onde a última igualdade deve-se à propriedade comutativa dos escalares $s_{ij}$. Comparando com \eqref{eq:S-quadrado}, conclui-se que $[(S^2)^T]_{ij} = [S^2]_{ij}$, ou seja, que $(S^2)^T = S^2$, o que significa que $S^2$ é simétrica.

\textbf{Observação:} Para uma verificação mais direta, sem comparar entradas individuais das matrizes, poderia ser usada o fato de que $(AB)^T = B^T A^T$:
\[
(S^2)^T = (S S)^T = S^T S^T = S S = S^2.
\]

Por este raciocínio fica fácil ver que as potências de uma matriz simétrica são simétricas:
\[
(S^n)^T
= (S \cdot \ldots \cdot S)^T
= S^T \cdot \ldots \cdot S^T
= S \cdot \ldots \cdot S = S^n.
\]

\item
\begin{enumerate}
\item Usando a definição de traço e as propriedades da adição, resulta que:
\begin{align*}
tr(A+B)
& = [A+B]_{11} + [A+B]_{22} + \ldots + [A+B]_{nn} \\
& = ([A]_{11} + [A]_{11}) + ([A]_{22} + [B]_{22}) + \ldots + ([A]_{nn} + [B]_{nn}) \\
& = ([A]_{11} + \dots + [A]_{nn}) + ([B]_{11} + \ldots + [B]_{nn})\\
& = tr(A)+tr(B).
\end{align*}
\item Segue da definição de traço e das propriedades da multiplicação por escalar que:
\begin{align*}
tr(cB)
& = [cA]_{11} + [cA]_{22} + \ldots + [cA]_{nn} \\
& = c[A]_{11} + c[A]_{22} + \ldots + c[A]_{nn} \\
& = c([A]_{11} + \dots + [A]_{nn}) \\
& = c \cdot tr(A).
\end{align*}
\item Como a diagonal principal não é alterada pela transposição de matrizes, e o traço só depende destas entradas, tem-se:
\begin{align*}
tr(A^T)
& = [A^T]_{11} + [A^T]_{22} + \ldots + [A^T]_{nn} \\
& = [A]_{11} + [A]_{22} + \ldots + [A]_{nn} \\
& = tr(A).
\end{align*}
\end{enumerate}
\end{enumerate}
\end{document}
